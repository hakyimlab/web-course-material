[
  {
    "objectID": "index-logistics.html",
    "href": "index-logistics.html",
    "title": "Logistics",
    "section": "",
    "text": "course checklist\n\n\n\n\n\n\nlogistics\n\n\n\n\n\n\n\n\n\nMar 19, 2023\n\n\nHaky Im\n\n\n\n\n\n\nNo matching items\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "index-bios-25328.html",
    "href": "index-bios-25328.html",
    "title": "BIOS25328",
    "section": "",
    "text": "This page contains material for the BIOS25328 Cancer Genetics and Genomics course, starting from 2024. 2023 and prior material is here\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 2\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 4 - statistical significance in gwas - addressing multiple testing\n\n\n\n\n\n\nlecture\n\n\nbios25328\n\n\n\nLecture 4\n\n\n\n\n\nMar 31, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 4 - multiple testing correction - with code\n\n\n\n\n\n\nbios25328\n\n\nnotebook\n\n\n\nLecture 4\n\n\n\n\n\nMar 31, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 1\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nMar 31, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 3\n\n\n\n\n\n\nlecture\n\n\nbios25328\n\n\n\nLecture 3\n\n\n\n\n\nMar 31, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 2\n\n\n\n\n\n\nlecture\n\n\nbios25328\n\n\n\nLecture 2: Cancer GWAS\n\n\n\n\n\nMar 26, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 5\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nApr 19, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlab 4\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2024\n\n\nLiz Gibbons\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 4\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nApr 12, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 8\n\n\n\n\n\n\nbios25328\n\n\nlecture\n\n\n\n\n\n\n\n\n\nApr 10, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 7\n\n\n\n\n\n\nbios25328\n\n\nlecture\n\n\n\n\n\n\n\n\n\nApr 8, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlab 3\n\n\n\n\n\n\nbios25328\n\n\nlab\n\n\n\nIn this lab, you will run all the steps of a GWAS analysis using the Marees et al tutorial.\n\n\n\n\n\nApr 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 3\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nApr 5, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 6\n\n\n\n\n\n\nbios25328\n\n\nlecture\n\n\n\n\n\n\n\n\n\nApr 3, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 5\n\n\n\n\n\n\nbios25328\n\n\nlecture\n\n\n\n\n\n\n\n\n\nApr 1, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlab 2\n\n\n\n\n\n\nbios25328\n\n\nlab\n\n\n\n\n\n\n\n\n\nMar 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 3\n\n\n\n\n\n\nbios25328\n\n\nlecture\n\n\n\n\n\n\n\n\n\nMar 25, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 2\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nMar 25, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 2\n\n\n\n\n\nDissection of Genetics & Prediction of Cancer Risk: Methods & Tools\n\n\n\n\n\nMar 20, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlab 1 - command line and R\n\n\n\n\n\n\nbios25328\n\n\nlab\n\n\n\n\n\n\n\n\n\nMar 18, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 1\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nMar 18, 2024\n\n\nHaky Im\n\n\n\n\n\n\nNo matching items\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/stat-gen-quick-training.html",
    "href": "post/qgt/2024-06-24-QGT-workbook/stat-gen-quick-training.html",
    "title": "quick training in statistical genetics",
    "section": "",
    "text": "I taught today the QGT course organized by Iuliana at Columbia for the 5th time. Participants asked for material for a quick training material in statistical genomics. It’s hard to choose one topic over the other one. So here is a biased selection of material that may help.\n\nRead “a brief history of human disease genetics” (nicely written summary of the development in the last two decades) https://www.nature.com/articles/s41586-019-1879-7\nRead GTExs flagship paper and very thorough supplementary material https://science.sciencemag.org/content/369/6509/1318\n\n\nalso read the GTEx working group’s paper for suggested practices to apply GTEx resources to GWAS https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02252-4\n\n\nRead the ENCODE paper https://www.nature.com/articles/s41586-020-2493-4\nGWAS tutorial Marees et al (https://course-material.hakyimlab.org/post/bios-25328/2024-04-05-lab-03/)\n\nhttps://course-material.hakyimlab.org/index-bios-25328 This is my portion of the cancer genetics and genomics course where I teach an lightweight intro to statistical genetics\nGenetic and molecular architecture of complex traits https://doi.org/10.1016/j.cell.2024.01.023\n\n\n\n\n\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/qgt/2023-06-10-QGT-workbook/setup.html",
    "href": "post/qgt/2023-06-10-QGT-workbook/setup.html",
    "title": "Lab Setup",
    "section": "",
    "text": "copied from QGT 2023 posit\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/qgt/2023-06-10-QGT-workbook/setup.html#setting-up-your-own-system",
    "href": "post/qgt/2023-06-10-QGT-workbook/setup.html#setting-up-your-own-system",
    "title": "Lab Setup",
    "section": "Setting up your own system",
    "text": "Setting up your own system\nLinux is the operating system of choice to run bioinformatics software. You will need either a computer running linux or or mac os, which has a linux-like environment.\n\ninstall anaconda/miniconda\ndefine imlabtools conda environment how to here, which will install all the python modules needed for this analysis session\ndownload data and software from Box. This will have copies of all the software repositories and the models\ndownload software\n\ndownload metaxcan repo\ndownload torus repo\n\ndownload prediction models from predictdb.org\ninstall R/RStudio/tidyverse package\ngit clone https://github.com/hakyimlab/QGT-Columbia-HKI.git\nstart Rstudio (if you installed workflowr, you can just open the QGT-Columbia-HKI.Rproj)\n\n#R setup\n\n\nShow the code\n#install R packages \ninstall.packages(\"remotes\")\nlibrary(remotes)\nremotes::install_github(\"stephenslab/susieR\") #gives the most up to date SusieR \ninstall.packages(\"coloc\")\ninstall.packages(\"tidyverse\")\n\n#install.packages(\"R.utils\")\n\n#install.packages(\"remotes\")\n# remotes::install_github(\"simingz/ctwas\", ref = \"develop\")\n\n## make sure these are installed\n# library(data.table)\n# library(BEDMatrix)\n# library(Rfast)\n# library(susieR)\n# library(coloc)\n\n#installing base miniconda\ninstall.packages(\"keras\")\nreticulate::install_miniconda(\"miniconda\")\n\n\n#Setting up Conda Environment\n\n\nShow the code\n#adding path\nexport PATH=$PATH:/cloud/project/miniconda/bin\n# adding repos/data\ngit clone https://github.com/hakyimlab/QGT-Columbia-HKI-repo.git\ngit clone https://github.com/hakyimlab/MetaXcan.git\nconda config --append channels conda-forge\nconda config --append channels bioconda\nconda env create -f /cloud/project/MetaXcan/software/conda_env.yaml\nconda activate imlabtools\n\n\nSet the Ram to 5gb in order to create the environment.\n#Box Data To upload the data. I first downloaded the box folder onto a local machine and then compressed the folders in the box folder to upload onto the server.\nNotes: For some reason setting up the environment and uploading the data will continue to use a lot of background RAM set sure to close the project and reopen to close extraneous programs."
  },
  {
    "objectID": "post/bios-25328/2025-03-31-lecture-03/index.html",
    "href": "post/bios-25328/2025-03-31-lecture-03/index.html",
    "title": "lecture 3",
    "section": "",
    "text": "Find the lecture notes here.\n\n\n\n\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2025-03-31-hw-01/index.html",
    "href": "post/bios-25328/2025-03-31-hw-01/index.html",
    "title": "homework 1",
    "section": "",
    "text": "Homeworks problems for week 1\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2025-03-31-hw-01/index.html#self-assessment-quiz-10-points",
    "href": "post/bios-25328/2025-03-31-hw-01/index.html#self-assessment-quiz-10-points",
    "title": "homework 1",
    "section": "1. Self assessment quiz (10 points)",
    "text": "1. Self assessment quiz (10 points)\nGo through the lecture 1 self-assessment quiz. Feel free to use multiple attempts."
  },
  {
    "objectID": "post/bios-25328/2025-03-31-hw-01/index.html#run-the-lab-1-and-show-your-work-10-points",
    "href": "post/bios-25328/2025-03-31-hw-01/index.html#run-the-lab-1-and-show-your-work-10-points",
    "title": "homework 1",
    "section": "2. Run the lab 1 and show your work (10 points)",
    "text": "2. Run the lab 1 and show your work (10 points)"
  },
  {
    "objectID": "post/bios-25328/2025-03-31-hw-01/index.html#edit-the-bash-scripts-from-the-lab-and-show-your-work-20-points",
    "href": "post/bios-25328/2025-03-31-hw-01/index.html#edit-the-bash-scripts-from-the-lab-and-show-your-work-20-points",
    "title": "homework 1",
    "section": "3. Edit the bash scripts from the lab and show your work (20 points)",
    "text": "3. Edit the bash scripts from the lab and show your work (20 points)\n\nFor the 01_init.sh part:\n\nTask: Modify the script to create files with a different year (e.g., 2021 instead of 2020) in the file names.\nLearning Objective: This task will help understand how to modify string literals in bash scripts.\n\nFor the 02_fix_filenames.sh part:\n\nTask: Modify the script to rename files using a different date format (e.g., MM-DD-YYYY instead of YYYY-MM-DD).\nLearning Objective: This task will teach your how to use the sed command for more complex pattern matching and substitution.\n\nFor the 03_process_data.sh part:\n\nTask: Modify the script to calculate the sum of the readings in addition to the average.\nLearning Objective: This task will help you understand how to perform arithmetic operations in bash and work with loops.\n\nFor the 04_geo.sh part:\n\nTask: Modify the script to print a message saying “Download complete” after downloading the gene expression data file.\nLearning Objective: This task will help you understand how to add simple print statements to provide user feedback in bash scripts.\n\nFor the 05_filter_geo.sh part:\n\nTask: Modify the script to create a new file called filtered_results.csv that contains the filtered records, instead of displaying them on the screen.\nLearning Objective: This task will teach you how to redirect output to a file in bash scripts.\n\nFor the 99_clean_all.sh part:\n\nTask: Modify the script to print a message saying “Directory cleaned” after deleting all the files and removing the directory.\nLearning Objective: This task will help you understand how to add print statements to confirm the completion of a task in bash scripts.\n\n\nQuiz questions selected and edited from content generated with chatGPT"
  },
  {
    "objectID": "post/bios-25328/2024-03-20-lecture-02-gene-mapping-GWAS/index.html",
    "href": "post/bios-25328/2024-03-20-lecture-02-gene-mapping-GWAS/index.html",
    "title": "lecture 2",
    "section": "",
    "text": "Lecture 2 notes in keynote\n\n\n\n\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-03-20-hw-01/index.html",
    "href": "post/bios-25328/2024-03-20-hw-01/index.html",
    "title": "homework 1",
    "section": "",
    "text": "Homeworks problems for week 1\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-03-20-hw-01/index.html#self-assessment-quiz-10-points",
    "href": "post/bios-25328/2024-03-20-hw-01/index.html#self-assessment-quiz-10-points",
    "title": "homework 1",
    "section": "1. Self assessment quiz (10 points)",
    "text": "1. Self assessment quiz (10 points)\nGo through the lecture 1 self-assessment quiz. Feel free to use multiple attempts."
  },
  {
    "objectID": "post/bios-25328/2024-03-20-hw-01/index.html#run-the-lab-1-and-show-your-work-10-points",
    "href": "post/bios-25328/2024-03-20-hw-01/index.html#run-the-lab-1-and-show-your-work-10-points",
    "title": "homework 1",
    "section": "2. Run the lab 1 and show your work (10 points)",
    "text": "2. Run the lab 1 and show your work (10 points)"
  },
  {
    "objectID": "post/bios-25328/2024-03-20-hw-01/index.html#edit-the-bash-scripts-from-the-lab-and-show-your-work-10-points",
    "href": "post/bios-25328/2024-03-20-hw-01/index.html#edit-the-bash-scripts-from-the-lab-and-show-your-work-10-points",
    "title": "homework 1",
    "section": "3. Edit the bash scripts from the lab and show your work (10 points)",
    "text": "3. Edit the bash scripts from the lab and show your work (10 points)\n\nFor the 01_init.sh part:\n\nTask: Modify the script to create files with a different year (e.g., 2021 instead of 2020) in the file names.\nLearning Objective: This task will help understand how to modify string literals in bash scripts.\n\nFor the 02_fix_filenames.sh part:\n\nTask: Modify the script to rename files using a different date format (e.g., MM-DD-YYYY instead of YYYY-MM-DD).\nLearning Objective: This task will teach your how to use the sed command for more complex pattern matching and substitution.\n\nFor the 03_process_data.sh part:\n\nTask: Modify the script to calculate the sum of the readings in addition to the average.\nLearning Objective: This task will help you understand how to perform arithmetic operations in bash and work with loops.\n\nFor the 04_geo.sh part:\n\nTask: Modify the script to print a message saying “Download complete” after downloading the gene expression data file.\nLearning Objective: This task will help you understand how to add simple print statements to provide user feedback in bash scripts.\n\nFor the 05_filter_geo.sh part:\n\nTask: Modify the script to create a new file called filtered_results.csv that contains the filtered records, instead of displaying them on the screen.\nLearning Objective: This task will teach you how to redirect output to a file in bash scripts.\n\nFor the 99_clean_all.sh part:\n\nTask: Modify the script to print a message saying “Directory cleaned” after deleting all the files and removing the directory.\nLearning Objective: This task will help you understand how to add print statements to confirm the completion of a task in bash scripts.\n\n\nQuiz selected and edited from content generated with chatGPT"
  },
  {
    "objectID": "post/bios-25328/2024-03-25-lecture-03/index.html",
    "href": "post/bios-25328/2024-03-25-lecture-03/index.html",
    "title": "lecture 3",
    "section": "",
    "text": "Lecture 3 notes link\n\n\n\n\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-04-05-lab-03/index.html",
    "href": "post/bios-25328/2024-04-05-lab-03/index.html",
    "title": "lab 3",
    "section": "",
    "text": "Read and summarize in a few sentences this GWAS tutorial paper https://onlinelibrary.wiley.com/doi/10.1002/mpr.1608\nDownload plink from LINK (choose the one corresponding to your operating system. If running on posit.cloud, you should choose the linux version even if you are accessing posit from a different operating system)\nCreate a github user if you don’t already have one\nGit clone the tutorial from the command line (run git clone &lt;https://github.com/MareesAT/GWA_tutorial.git&gt; on the terminal). You will need to unzip files that look like *.zip\nrun the QC and Association components of the tutorial\n\n1_Main_script_QC_GWAS.txt and 3_Main_script_association_GWAS.txt\n\nyou may want to download the hapmap data from here https://uchicago.box.com/s/hawatrohw6fthytguaww83njrf5i6ace\n\nyou may need to download plink (https://www.cog-genomics.org/plink/1.9/)\nThe tutorial is designed so that you need to run all the steps but since 2_Population_stratification.txt is quite computationally time consuming, you can skip it and just download the files you need to run associations here https://uchicago.box.com/s/ux2xkab6zhth0csazixqoj98xtjh7h0x\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-04-05-lab-03/index.html#instructions",
    "href": "post/bios-25328/2024-04-05-lab-03/index.html#instructions",
    "title": "lab 3",
    "section": "",
    "text": "Read and summarize in a few sentences this GWAS tutorial paper https://onlinelibrary.wiley.com/doi/10.1002/mpr.1608\nDownload plink from LINK (choose the one corresponding to your operating system. If running on posit.cloud, you should choose the linux version even if you are accessing posit from a different operating system)\nCreate a github user if you don’t already have one\nGit clone the tutorial from the command line (run git clone &lt;https://github.com/MareesAT/GWA_tutorial.git&gt; on the terminal). You will need to unzip files that look like *.zip\nrun the QC and Association components of the tutorial\n\n1_Main_script_QC_GWAS.txt and 3_Main_script_association_GWAS.txt\n\nyou may want to download the hapmap data from here https://uchicago.box.com/s/hawatrohw6fthytguaww83njrf5i6ace\n\nyou may need to download plink (https://www.cog-genomics.org/plink/1.9/)\nThe tutorial is designed so that you need to run all the steps but since 2_Population_stratification.txt is quite computationally time consuming, you can skip it and just download the files you need to run associations here https://uchicago.box.com/s/ux2xkab6zhth0csazixqoj98xtjh7h0x"
  },
  {
    "objectID": "post/bios-25328/2024-04-05-lab-03/index.html#notes",
    "href": "post/bios-25328/2024-04-05-lab-03/index.html#notes",
    "title": "lab 3",
    "section": "Notes",
    "text": "Notes\n\nSome modifications to the code may be needed. Use them if you encounter errors.\n\nRelatedness.R needs to change lines 7 and 15 to\nlegend(1,1, xjust=1, yjust=1, legend=levels(factor(relatedness$RT)), pch=16, col=c(4,3))\nlegend(0.02,1, xjust=1, yjust=1, legend=levels(factor(relatedness$RT)), pch=16, col=c(4,3))\nline 31 of 2_Main_script_MDS.txt replace\nplink --bfile ALL.2of4intersection.20100804.genotypes --set-missing-var-ids @:#[b37]\\$1,\\$2 --make-bed --out ALL.2of4intersection.20100804.genotypes_no_missing_IDs\nwith\nplink --bfile ALL.2of4intersection.20100804.genotypes --set-missing-var-ids '@:#[b37]$1,$2' --make-bed --out ALL.2of4intersection.20100804.genotypes_no_missing_IDs\nline 144 in 2_Main_script_MDS.txt replace\n(base) haekyungim@Im-Lab-016 1_QC_GWAS % cat race_1kG14.txt racefile_own.txt | sed -e '1i\\FID IID race' &gt; racefile.txt\nsed: 1: \"1i\\FID IID race\n\": extra characters after \\ at the end of i command\n(base) haekyungim@Im-Lab-016 1_QC_GWAS % cat race_1kG14.txt racefile_own.txt | sed -e '1i\\\nFID IID race' &gt; racefile.txt\ninstall qqman in R and comment out first line on Manhattan_plot.R and QQ_plot.R\n##install.packages(\"qqman\",repos=\"http://cran.cnr.berkeley.edu/\",lib=\"~\" ) # location of installation can be changed but has to correspond with the library location \n##library(\"qqman\",lib.loc=\"~\")  \nlibrary(\"qqman\")"
  },
  {
    "objectID": "post/bios-25328/2024-04-05-lab-03/index.html#questions",
    "href": "post/bios-25328/2024-04-05-lab-03/index.html#questions",
    "title": "lab 3",
    "section": "Questions",
    "text": "Questions\nUsing the output from the tutorial or using the commands you learned from it, answer the following questions. Show the command you used to create the result.\n\nHow many individuals are in the genotype file you downloaded? (5 pts)\nExplain the contents of .fam, .bim, .bed files (5 pts)\nWrite the captions for the figures generated by the commands in 1_Main_script_QC_GWAS.txt and 3_Main_script_association_GWAS (5 pts per figure caption)\nExplain what you accomplished with the tutorial and explain the results/figures you obtained. (20 pts)"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index.html",
    "href": "post/bios-25328/2025-04-02-lecture-04/index.html",
    "title": "lecture 4 - statistical significance in gwas - addressing multiple testing",
    "section": "",
    "text": "Find the lecture notes here.\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index.html#learning-objectives",
    "href": "post/bios-25328/2025-04-02-lecture-04/index.html#learning-objectives",
    "title": "lecture 4 - statistical significance in gwas - addressing multiple testing",
    "section": "learning objectives",
    "text": "learning objectives\nBy the end of this lecture, students should be able to:\n\nUnderstand the concept and risks of multiple hypothesis testing.\nCompute the probability of false negatives under multiple testing.\nApply Bonferroni correction and understand its limitations.\nInterpret genome-wide significance thresholds.\nUnderstand the distribution of p-values under null and alternative hypotheses.\nPerform and interpret simulations to explore p-value distributions.\nExplain the concept of False Discovery Rate (FDR) and how it differs from Family-Wise Error Rate (FWER).\nUse tools like the qvalue R package to calculate FDR-adjusted values.\nAnalyze and visualize empirical distributions of p-values using simulations."
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index.html#summary-of-the-lecture-notes",
    "href": "post/bios-25328/2025-04-02-lecture-04/index.html#summary-of-the-lecture-notes",
    "title": "lecture 4 - statistical significance in gwas - addressing multiple testing",
    "section": "summary of the lecture notes",
    "text": "summary of the lecture notes\n\nthe perils of multiple testing\n\nIllustrated using XKCD comic (#882).\nProbability of not rejecting the null hypothesis decreases with more tests.\n\nExample: With 100 tests at α = 0.05, the chance of not rejecting any is 0.0059.\n\n\n\n\nbonferroni correction\n\nAdjusts significance threshold to α / number of tests.\nVery conservative; reduces Type I error but increases Type II error.\n\n\n\ngenome-wide significance\n\nCommon threshold: 5 × 10-8\nEquivalent to Bonferroni correction for ~1 million tests.\n\n\n\ndistribution of p-values\n\nUnder null: Uniform distribution.\nUnder alternative: Skewed toward 0.\nBeta and Normal distributions considered.\n\n\n\nsimulations\n\nGenerate p-values for null and alternative hypotheses.\nSimulate genotype XX, phenotype YY, and error ϵϵ.\nPlot Y vs. X under both null and alternative scenarios.\n\n\n\nregression approach\n\nUnder null: Y = a + X * 0 + ϵ\nUnder alternative: Y = a + X * β + ϵ\n\n\n\nempirical distribution\n\nRun simulation 10,000 times.\nCreate histograms of p-values under different scenarios.\n\n\n\nmixed simulations\n\nMix of null and alternative cases.\nUseful to visualize real-world settings with both signal and noise.\n\n\n\nmultiple testing corrections\n\nFWER (Family-Wise Error Rate): probability of ≥1 false positives.\nFDR (False Discovery Rate): expected proportion of false positives among rejected hypotheses.\n\n\n\nq-value and π₀\n\nqvalue package estimates FDR-adjusted p-values.\nπ₀: proportion of tests under the null.\nπ₁ = 1 - π₀: proportion of true positives.\n\n\n\nreference\n\nStorey & Tibshirani (2003), foundational paper on FDR in genome-wide studies. Storey JD, Tibshirani R. Statistical significance for genomewide studies. Proc Natl Acad Sci U S A. 2003 Aug 5;100(16):9440-5. doi: 10.1073/pnas.1530509100. Epub 2003 Jul 25. PMID: 12883005; PMCID: PMC170937."
  },
  {
    "objectID": "post/bios-25328/2024-04-12-lab-04/index.html",
    "href": "post/bios-25328/2024-04-12-lab-04/index.html",
    "title": "lab 4",
    "section": "",
    "text": "In this lab we are going to use the PRSice software to take height GWAS results and predict height of the Personal Genome Project individuals using their genotype data.\n\n\n\nDownload data from box\nDownload PRSice\nRun exploratory analysis of data\nRun PRSice\nPlot observed versus predicted for height\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-04-12-lab-04/index.html#goals-and-introduction",
    "href": "post/bios-25328/2024-04-12-lab-04/index.html#goals-and-introduction",
    "title": "lab 4",
    "section": "",
    "text": "In this lab we are going to use the PRSice software to take height GWAS results and predict height of the Personal Genome Project individuals using their genotype data.\n\n\n\nDownload data from box\nDownload PRSice\nRun exploratory analysis of data\nRun PRSice\nPlot observed versus predicted for height"
  },
  {
    "objectID": "post/bios-25328/2024-04-12-lab-04/index.html#setup",
    "href": "post/bios-25328/2024-04-12-lab-04/index.html#setup",
    "title": "lab 4",
    "section": "Setup",
    "text": "Setup\n\nload R packages and define paths\nYou will have to install all these packages first:\n(r code block)\n\n\nShow the code\ninstall.packages(\"tidyverse\")\ninstall.packages(\"RSQLite\")\ninstall.packages(\"glue\")\n\n\n(r code block)\n\n\nShow the code\nsuppressMessages(library(tidyverse))\nsuppressMessages(library(RSQLite))\nsuppressMessages(library(glue))\n\n\n\n\nDownload data\n\ndownload the data from here and place it in a directory called DATA\ndownload PRSice software from https://choishingwan.github.io/PRSice/\n\nIf you are on a Mac install the mac appropriate binary:\n(bash code block)\n\n\nShow the code\n# wget https://github.com/choishingwan/PRSice/releases/download/2.3.5/PRSice_mac.zip\n\n\nIf you are on Posit cloud do the linux binary:\n(bash code block)\n\n\nShow the code\nwget https://github.com/choishingwan/PRSice/releases/download/2.3.5/PRSice_linux.zip\n\n\nUnzip the binary: (bash code block)\n\n\nShow the code\nunzip ./PRSice_linux.zip\n\n\nmove the executable to the directory where you keep your software (optional) ** the first time you run PRSice, it will install additional components make sure PRSice is executable ** chmod u+x PRSice\n(bash code block)\n\n\nShow the code\nchmod +x ./PRSice_linux\n\n\nTerminal Setup\n(bash code block)\n\n\nShow the code\nexport PRE=\"/cloud/project\"\nexport DATA=\"$PRE/Lab-personal-genomes-project-data\"\n\nexport PRSice=\"/cloud/project/\" # file/path/to/PRSice\nexport PRSice_os=\"PRSice_linux\" # optional: which operating system is your prsice named for\n#$PRSice/$PRSice_os --help\ncd $DATA\nexport WORK=$DATA"
  },
  {
    "objectID": "post/bios-25328/2024-04-12-lab-04/index.html#exploration-of-the-data",
    "href": "post/bios-25328/2024-04-12-lab-04/index.html#exploration-of-the-data",
    "title": "lab 4",
    "section": "Exploration of the Data",
    "text": "Exploration of the Data\n\nopen the database with phenotype information and list tables\n(r code block)\n\n\nShow the code\ndbname &lt;- paste0(DATA,\"/repgp-data.sqlite3\") ##This is just to create the file path to the sqlite3 file \n## connect to db\ndb = RSQLite::dbConnect(SQLite(), dbname)\n## list tables\ndbListTables(db)\n\n\nquery database users table\n(r code block)\n\n\nShow the code\ndbListFields(db,\"users\")\n\n\n(r code block)\n\n\nShow the code\nquery &lt;- function(...) dbGetQuery(db, ...)\nusers = query(\"select * from users\")\nnames(users)\n\n\nlook at distribution by count for each column\n(r code block)\n\n\nShow the code\nusers %&gt;% count(race)\n\n\n(r code block)\n\n\nShow the code\nusers  %&gt;% count(gender)\n\n\n(r code block)\n\n\nShow the code\nusers %&gt;% count(blood)\n\n\nplot height distribution by gender\n(r code block)\n\n\nShow the code\nusers %&gt;% ggplot(aes(height,fill=gender)) + geom_density(alpha=0.6) + ggtitle(\"Height by gender - Missing gender, *, has bi-modal distr.\") + theme_minimal(base_size = 15)"
  },
  {
    "objectID": "post/bios-25328/2024-04-12-lab-04/index.html#run-prsice",
    "href": "post/bios-25328/2024-04-12-lab-04/index.html#run-prsice",
    "title": "lab 4",
    "section": "run PRSice",
    "text": "run PRSice\n\ncreate phenotype data file\ncreate phenotype data file as intersection of the plink formatted fam file and the users table from the database repgp-data.sqlite3\n(r code block)\n\n\nShow the code\nfam = read_tsv(glue::glue(\"{DATA}/repgp.fam\"),col_names = FALSE)\n\n\n(r code block)\n\n\nShow the code\nnames(fam)[1:2] = c(\"FID\",\"IID\")\nfam &lt;- fam %&gt;% select(FID, IID) %&gt;% inner_join(users %&gt;% select(sample,height,weight,gender), by=c(\"IID\"=\"sample\")) \nwrite_tsv(fam,file=glue::glue(\"{DATA}/phenodata.txt\"))\n\n\nexecute bash command to run PRSice\n(bash code block)\n\n\nShow the code\nmkdir /cloud/project/Lab-personal-genomes-project-data/output\n\nRscript /cloud/project/PRSice.R --dir /cloud/project \\\n    --prsice /cloud/project/PRSice_linux \\\n    --base /cloud/project/Lab-personal-genomes-project-data/ukb_height.gz \\\n    --target cloud/project/Lab-personal-genomes-project-data/repgp.chr# \\\n    --snp variant_id \\\n    --A1 effect_allele \\\n    --A2 non_effect_allele \\\n    --stat effect_size \\\n    --beta \\\n    --pvalue pvalue \\\n    --pheno-file /cloud/project/Lab-personal-genomes-project-data/phenodata.txt \\\n    --pheno-col height \\\n    --bar-levels 5e-08,5e-07,5e-06,5e-05,5e-04,5e-03,5e-02,5e-01,1 \\\n    --fastscore \\\n    --binary-target F \\\n    --thread 2 \\\n    --out /cloud/project/Lab-personal-genomes-project-data/output/height_score_all\n\n\nIf you get duplicated SNP ID, follow the instructions\n(bash code block)\n\n\nShow the code\nPRSice=\"/cloud/project/\"\nWORK=\"/cloud/project/Lab-personal-genomes-project-data/\"\n\nRscript $PRSice/PRSice.R --dir $PRSice \\\n    --prsice $PRSice/PRSice_mac \\\n    --base $WORK/ukb_height.gz \\\n    --extract $WORK/output/height_score_all.valid \\\n    --target $WORK/repgp.chr# \\\n    --snp variant_id \\\n    --A1 effect_allele \\\n    --A2 non_effect_allele \\\n    --stat effect_size \\\n    --beta \\\n    --pvalue pvalue \\\n    --pheno-file $WORK/phenodata.txt \\\n    --pheno-col height \\\n    --bar-levels 5e-08,5e-07,5e-06,5e-05,5e-04,5e-03,5e-02,5e-01,1 \\\n    --fastscore \\\n    --binary-target F \\\n    --thread 2 \\\n    --out $WORK/output/height_score_all\n\n\nThis may take a couple minutes\nplot observed vs predicted height\n(r code block)\n\n\nShow the code\n## we already have the phenotype data in the fam variable\npredicted_height = read_delim(glue::glue(\"{DATA}/output/height_score_all.best\"),delim=\" \")\n\n\n(r code block)\n\n\nShow the code\ncombined &lt;- predicted_height %&gt;% inner_join(fam,by=c(\"IID\"=\"IID\")) \ncombined %&gt;% ggplot(aes(PRS,height)) + geom_point() + theme_minimal(base_size = 15)\n\n\nregress observed height with predicted height (PRS)\n(r code block)\n\n\nShow the code\nsummary(lm(height ~ PRS,data=combined)) %&gt;% coef()"
  },
  {
    "objectID": "post/bios-25328/2024-04-19-homework-05/index.html",
    "href": "post/bios-25328/2024-04-19-homework-05/index.html",
    "title": "homework 5",
    "section": "",
    "text": "Lecture 9 assessment quiz (10 points)\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-04-19-homework-05/index.html#a.-complete-the-following-assessments",
    "href": "post/bios-25328/2024-04-19-homework-05/index.html#a.-complete-the-following-assessments",
    "title": "homework 5",
    "section": "",
    "text": "Lecture 9 assessment quiz (10 points)"
  },
  {
    "objectID": "post/bios-25328/2024-04-03-lecture-06/index.html",
    "href": "post/bios-25328/2024-04-03-lecture-06/index.html",
    "title": "lecture 6",
    "section": "",
    "text": "Lecture 6 notes link\n\n\n\n\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/images/2024-03-25-GWAS/index.html",
    "href": "post/images/2024-03-25-GWAS/index.html",
    "title": "Images GWAS",
    "section": "",
    "text": "Show the code\nFOLDER=\"/Users/haekyungim/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/data-Github/web-data/images\"\nknitr::include_graphics(paste0(FOLDER,\"/\",\"2024-03-25-GWAS/GWAS.png\"))\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/images/2024-03-25-GWAS/index.html#gwas",
    "href": "post/images/2024-03-25-GWAS/index.html#gwas",
    "title": "Images GWAS",
    "section": "",
    "text": "Show the code\nFOLDER=\"/Users/haekyungim/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/data-Github/web-data/images\"\nknitr::include_graphics(paste0(FOLDER,\"/\",\"2024-03-25-GWAS/GWAS.png\"))"
  },
  {
    "objectID": "index-qgt.html",
    "href": "index-qgt.html",
    "title": "QGT",
    "section": "",
    "text": "This page contains material for the Quantitative Genomic Training course material. Prior material was in https://lab-notes.hakyimlab.org/post/2022-06-10-qgt-training/index.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nquick training in statistical genetics\n\n\n\n\n\nmaterial for introduction to statistical genetics\n\n\n\n\n\nJun 25, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome QGT Training 2024\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nLab Setup\n\n\n\n\n\n\n\n\n\n\n\nMay 6, 2022\n\n\n\n\n\n\nNo matching items\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2025-03-26-lecture-02/index.html",
    "href": "post/bios-25328/2025-03-26-lecture-02/index.html",
    "title": "lecture 2",
    "section": "",
    "text": "This lecture introduces the foundational concepts, historical context, and modern methods used to identify genetic risk factors for cancer, with a focus on germline susceptibility. It begins with linkage analysis, highlighting its role in the discovery of high-penetrance genes such as BRCA1/2 and APC, and contrasts it with genome-wide association studies (GWAS), which leverage high-throughput genotyping and large population cohorts to identify many low-penetrance variants. The course explains the statistical framework for GWAS, including hypothesis testing, regression models, and visualizations like Manhattan and QQ plots. Emphasis is placed on the polygenic nature of most cancer risks, the interpretation of GWAS results, and landmark studies such as the Wellcome Trust Case Control Consortium (WTCCC). The session also includes practical considerations for students, such as homework expectations and lab setup. (LLM-generated summary)\nFind the lecture notes here.\n\n\n\n\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-04-08-lecture-07-prs/index.html",
    "href": "post/bios-25328/2024-04-08-lecture-07-prs/index.html",
    "title": "lecture 7",
    "section": "",
    "text": "Lecture 7 notes link\n\n\n\n\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-04-10-lecture-08-QTL/index.html",
    "href": "post/bios-25328/2024-04-10-lecture-08-QTL/index.html",
    "title": "lecture 8",
    "section": "",
    "text": "Lecture 8 notes link\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-04-10-lecture-08-QTL/index.html#download-the-gwas-catalog",
    "href": "post/bios-25328/2024-04-10-lecture-08-QTL/index.html#download-the-gwas-catalog",
    "title": "lecture 8",
    "section": "Download the GWAS catalog",
    "text": "Download the GWAS catalog\n\n\nShow the code\nsuppressMessages(library(tidyverse))\n\n\nWarning: package 'purrr' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\nShow the code\nsuppressMessages(library(glue))\n\n\nWarning: package 'glue' was built under R version 4.3.3\n\n\nShow the code\n##PRE = \"/Users/haekyungim/Library/CloudStorage/Box-Box/LargeFiles/imlab-data/data-Github/web-data\"\nPRE=\"~/Downloads/\"\nDATA = glue(\"{PRE}/2024-04-10-gwas-catalog-analysis-2022\")\nif(!file.exists(DATA)) system(glue(\"mkdir -p {DATA}\"))\nWORK=DATA\n\nDOWNLOAD_DATE=\"2024-04-10\"\n\n## download data from GWAS catalog\n## https://www.ebi.ac.uk/gwas/docs/file-downloads\n\n# - [ ] make sure the DATAFILE name is the same as the one you just downloaded\n# DATAFILE = \"gwas_catalog_v1.0.2-associations_e105_r2022-04-07.tsv\"\nDATAFILE=\"full\"\nfilename = glue(\"{DATA}/{DATAFILE}\")\n\nif(!file.exists(filename)) system(glue(\"wget -P {DATA} https://www.ebi.ac.uk/gwas/api/search/downloads/full\"))\n\n\n\n\nShow the code\ngwascatalog = read_tsv(filename)\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 624399 Columns: 34\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (23): FIRST AUTHOR, JOURNAL, LINK, STUDY, DISEASE/TRAIT, INITIAL SAMPLE...\ndbl   (9): PUBMEDID, UPSTREAM_GENE_DISTANCE, DOWNSTREAM_GENE_DISTANCE, MERGE...\ndate  (2): DATE ADDED TO CATALOG, DATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nShow the code\ndim(gwascatalog)\n\n\n[1] 624399     34\n\n\nShow the code\nnames(gwascatalog)\n\n\n [1] \"DATE ADDED TO CATALOG\"      \"PUBMEDID\"                  \n [3] \"FIRST AUTHOR\"               \"DATE\"                      \n [5] \"JOURNAL\"                    \"LINK\"                      \n [7] \"STUDY\"                      \"DISEASE/TRAIT\"             \n [9] \"INITIAL SAMPLE SIZE\"        \"REPLICATION SAMPLE SIZE\"   \n[11] \"REGION\"                     \"CHR_ID\"                    \n[13] \"CHR_POS\"                    \"REPORTED GENE(S)\"          \n[15] \"MAPPED_GENE\"                \"UPSTREAM_GENE_ID\"          \n[17] \"DOWNSTREAM_GENE_ID\"         \"SNP_GENE_IDS\"              \n[19] \"UPSTREAM_GENE_DISTANCE\"     \"DOWNSTREAM_GENE_DISTANCE\"  \n[21] \"STRONGEST SNP-RISK ALLELE\"  \"SNPS\"                      \n[23] \"MERGED\"                     \"SNP_ID_CURRENT\"            \n[25] \"CONTEXT\"                    \"INTERGENIC\"                \n[27] \"RISK ALLELE FREQUENCY\"      \"P-VALUE\"                   \n[29] \"PVALUE_MLOG\"                \"P-VALUE (TEXT)\"            \n[31] \"OR or BETA\"                 \"95% CI (TEXT)\"             \n[33] \"PLATFORM [SNPS PASSING QC]\" \"CNV\"                       \n\n\n\n\nShow the code\n## show number of entries in the GWAS catalog with cancer\ngwascatalog %&gt;% select(`DISEASE/TRAIT`, MAPPED_GENE) %&gt;% filter(grepl(\"cancer\",`DISEASE/TRAIT`)) %&gt;% dim()\n\n\n[1] 11391     2\n\n\n\nNumber of distinct loci reported in GWAS of various cancers\n\nNumber of entries in the GWAS catalog with cancer, unique loci (it’s a reasonable assumption that mapped genes will be a good way to count loci)\n\n\nShow the code\ngwascatalog %&gt;% select(`DISEASE/TRAIT`, MAPPED_GENE) %&gt;% filter(grepl(\"cancer\",`DISEASE/TRAIT`)) %&gt;% unique() %&gt;% dim()\n\n\n[1] 6736    2\n\n\n\n\nShow the code\n## plot histogram of GWAS loci by year\ngwascat_sig = gwascatalog %&gt;% mutate(year=as.factor(lubridate::year(lubridate::as_date(`DATE ADDED TO CATALOG`)))) %&gt;% filter(`P-VALUE`&lt;5e-8)\n\ngwascat_sig %&gt;% filter(year!=\"2024\") %&gt;% ggplot(aes(year)) + geom_bar() + theme_bw(base_size = 15) + scale_x_discrete(breaks=c(\"2008\",\"2012\",\"2016\",\"2020\",\"2022\")) + xlab(\"year\") + ylab(\"GWAS loci reported p&lt;5e-8\") + ggtitle(paste0(\"GWAS Catalog Downloaded \",DOWNLOAD_DATE) )\n\n\n\n\n\n\n\n\n\nShow the code\n##ggsave(glue::glue(\"{DATA}/gwas-catalog/gwas-catalog-by-year.pdf\"))"
  },
  {
    "objectID": "post/bios-25328/2024-03-18-lab-01-command-line-R/index.html",
    "href": "post/bios-25328/2024-03-18-lab-01-command-line-R/index.html",
    "title": "lab 1 - command line and R",
    "section": "",
    "text": "We will learn to use the command line by doing. Follow the instructions below.\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-03-18-lab-01-command-line-R/index.html#command-line",
    "href": "post/bios-25328/2024-03-18-lab-01-command-line-R/index.html#command-line",
    "title": "lab 1 - command line and R",
    "section": "command line",
    "text": "command line\n\nread the article that explains why it is a good idea to learn to use the command line Five reasons why researchers should learn to love the command line\nAnswer the questions showing that you did read the paper link to questions. You have multiple attempts.\nfollow the instructions on the paper’s github README page copied below for your convenience.\n\n\nIf you are on a Mac or Linux, open your Terminal (or similar) application. On Windows, you’ll need something like MobaXterm.\nFrom the command prompt, clone this GitHub repository: git clone https://github.com/jperkel/nature_bash.git.\nEnter the newly created directory: cd nature_bash.\nMake the scripts executable: chmod +x *.sh.\nRun the scripts in numeric order, being sure to prepend each file name with a period and slash, eg: ./01_init.sh). This tells the shell where to find these scripts (i.e., the current directory) when that location is not included in your file search PATH variable.\nYou don’t have to type the complete filename. Once you type enough of the filename to be uniquely recognized, you can use Bash’s ‘autocomplete’ feature to fill in the rest of the name for you. Try it: type ./01 and then hit the TAB key to complete the command.\n\nThere are six scripts in total:\n\n01_init.sh: Creates a temporary directory (nature_tmpdir) beneath the current directory and fills it with dummy files\n02_fix_filenames.sh: We created 217 files with date-stamped names using the pattern: DD-MM-YYYY, e.g., datafile-01-01-2020.txt, datafile-02-01-2020.txt, etc. This script uses the sed command and a for-loop to rename them using the standard YYYYMMDD pattern.\n03_process_data.sh: We created a four dummy data files, such as might be output from a spectrophotometer (3 files of “readings” and 1 “background” file). This script pulls those data into a single data file, averages the readings, subtracts the background, and divides by 60 to give a per-second value. The result is a spreadsheet, which is displayed on screen.\n04_geo.sh: This script downloads a compressed gene expression datafile from the NCBI Gene Expression Omnibus database, extracts it, and searches for a gene name given on the command line. Try it with the Cactin gene: ./04_geo.sh Cactin.\n05_filter_geo.sh: This script uses sed and awk to filter the GEO datafile from 04_geo.sh for records with a p-value &lt; 0.05 and an ensembl_gene_id value other than NA.\n99_clean_all.sh: Deletes all temporary files.\n\nFeel free to use chatGPT or similar to explain the scripts if you are not familiar with these commands."
  },
  {
    "objectID": "post/bios-25328/2024-03-18-lab-01-command-line-R/index.html#r-introduction",
    "href": "post/bios-25328/2024-03-18-lab-01-command-line-R/index.html#r-introduction",
    "title": "lab 1 - command line and R",
    "section": "R introduction",
    "text": "R introduction\nYou are probably familiar with R. If not, start learning with swirl\n\ninstall.packages(\"swirl\")\nlibrary(\"swirl\")\nswirl()"
  },
  {
    "objectID": "post/bios-25328/2024-03-18-lab-01-command-line-R/index.html#command-line-basics",
    "href": "post/bios-25328/2024-03-18-lab-01-command-line-R/index.html#command-line-basics",
    "title": "lab 1 - command line and R",
    "section": "Command line basics",
    "text": "Command line basics\nFor the bare minimum list of commands check out this link"
  },
  {
    "objectID": "post/bios-25328/2025-04-07-hw-02/index.html",
    "href": "post/bios-25328/2025-04-07-hw-02/index.html",
    "title": "homework 2",
    "section": "",
    "text": "This assignment focuses on simulating multiple testing scenarios, understanding p-value distributions, and applying correction methods.\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2025-04-07-hw-02/index.html#part-1-lecture-quizzes-20-points",
    "href": "post/bios-25328/2025-04-07-hw-02/index.html#part-1-lecture-quizzes-20-points",
    "title": "homework 2",
    "section": "Part 1: Lecture Quizzes (20 points)",
    "text": "Part 1: Lecture Quizzes (20 points)\n\nLecture 3 assessment quiz (10 points)\nLecture 4 assessment quiz (10 points)"
  },
  {
    "objectID": "post/bios-25328/2025-04-07-hw-02/index.html#part-2.-multiple-testing-simulation-80-points",
    "href": "post/bios-25328/2025-04-07-hw-02/index.html#part-2.-multiple-testing-simulation-80-points",
    "title": "homework 2",
    "section": "Part 2. Multiple testing simulation (80 points)",
    "text": "Part 2. Multiple testing simulation (80 points)\n\nGoal: Simulate multiple tests to explore p-value behavior, FWER, and FDR.\n\n\nParameters:\n\nSamples per sim: N = 100\nEffect size (alt): beta = 1\nNumber of sims: 10000\nTrue null proportion: pi0 = 0.9\nSignificance level: alpha = 0.05\nModels: X=rnorm(N), eps=rnorm(N), Ynull=0X+eps, Yalt=betaX+eps\n\n\n\nTasks:\n\n2.1. Simulation Run (10 pts)\n\nRun 10,000 simulations. In each:\nGenerate X, Ynull, Yalt.\nFit lm(Ynull ~ X) and lm(Yalt ~ X).\nStore the p-value for X from both models.\nCreate two vectors: p_null and p_alt (10,000 p-values each).\n\n\n\n2.2. P-value Distributions (10 pts)\n\nPlot histograms for p_null and p_alt.\nInterpret their shapes (Why uniform? Why skewed?).\n\n\n\n2.3. Mixed P-values (10 pts)\n\nCreate a logical vector is_null (length 10k, pi0 proportion TRUE). Shuffle it.\nCreate p_mixed by selecting from p_null if is_null is TRUE, else from p_alt.\nPlot a histogram and a QQ plot (p_mixed vs. uniform quantiles, add y=x line).\nInterpret the QQ plot (adherence to and deviation from the line).\n\n\n\n2.4. Confusion Matrix & Reality Check (15 pts)\n\nUsing p_mixed, is_null, and alpha = 0.05, calculate the counts for TN, FP, FN, TP.\nIn real data analysis, can this table be perfectly known? Explain why/why not.\n\n\n\n2.5. Bonferroni Correction (15 pts)\n\nCalculate the Bonferroni-adjusted threshold for p_mixed.\nHow many tests are significant using this threshold?\nRecalculate TN, FP, FN, TP counts with the Bonferroni threshold.\nDiscuss the FP vs. TP trade-off compared to the uncorrected alpha = 0.05.\n\n\n\n2.6. FDR Control with qvalue (20 pts)\n\nUse qvalue::qvalue() on p_mixed.\nReport the estimated pi0 from the result. How does it compare to the true pi0 used?\nHow many tests are significant at an FDR threshold of 0.1 (q-value ≤ 0.1)?\nCompare this number of significant tests to the numbers from the uncorrected and Bonferroni approaches.\nBriefly state the conceptual difference between controlling FWER and FDR.\n\n\n\n\nExtra Credit\n\nEC.1. More realistic genotype predictor (+10 points)\n\nRerun key parts of the simulation (e.g., 2.1-2.6) using X simulated as genotypes {0, 1, 2} assuming MAF=0.3 and Hardy-Weinberg Equilibrium. You will want to use rbinom(nsam,2,0.3) to simulate genotypes. Report key findings/differences.\n\n\n\nEC.2. Binary trait (+10 points)\n\nRerun key parts using a simulated binary trait Y (dependent on X for alternatives) and logistic regression (glm(Y ~ X, family=binomial)) to obtain p-values. Report key findings/differences."
  },
  {
    "objectID": "post/bios-25328/2025-04-07-hw-02/index.html#submission-guidelines",
    "href": "post/bios-25328/2025-04-07-hw-02/index.html#submission-guidelines",
    "title": "homework 2",
    "section": "Submission Guidelines",
    "text": "Submission Guidelines\nSubmit a single, runnable, commented R script (.R) or R Markdown (.Rmd). Include all code, generated plots, and written answers/interpretations clearly labeled.\nHint: feel free to use the code from the lecture slides or here"
  },
  {
    "objectID": "post/bios-25328/2024-03-29-lab-02/index.html",
    "href": "post/bios-25328/2024-03-29-lab-02/index.html",
    "title": "lab 2",
    "section": "",
    "text": "get started with simulations for homework 2\n\n\n\n\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-04-01-homework-03/index.html",
    "href": "post/bios-25328/2024-04-01-homework-03/index.html",
    "title": "homework 3",
    "section": "",
    "text": "Lecture 5 assessment quiz (10 points)\nLecture 6 assessment quiz (10 points)\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-04-01-homework-03/index.html#a.-complete-the-following-assessments",
    "href": "post/bios-25328/2024-04-01-homework-03/index.html#a.-complete-the-following-assessments",
    "title": "homework 3",
    "section": "",
    "text": "Lecture 5 assessment quiz (10 points)\nLecture 6 assessment quiz (10 points)"
  },
  {
    "objectID": "post/bios-25328/2024-04-01-homework-03/index.html#b.-reproduce-figures-and-analysis-in-lectures-5-and-6-80-points",
    "href": "post/bios-25328/2024-04-01-homework-03/index.html#b.-reproduce-figures-and-analysis-in-lectures-5-and-6-80-points",
    "title": "homework 3",
    "section": "B. Reproduce figures and analysis in lectures 5 and 6 (80 points)",
    "text": "B. Reproduce figures and analysis in lectures 5 and 6 (80 points)\n\nDownload HapMap3 chromosome 22 data (5pt)\n\n\nYou can find the full HapMap 3 genotype data with other useful information here\n\n\nDownload Growth Data (5pt) here\n\n\nif you want background information on this trait you can read this paper)\n\n\nCalculate PCs using plink (10pt)\nPlot the first two principal components of the genotype matrix, color by population (10pt)\nRun GWAS of growth with and without adjusting for PCs (20pt)\n\nshow qqplot and manhattan plot for each (10pt)\n\nCreate HapMap Trios Relatedness Matrix (10pt)\ngenerate a tileplot to visualize the population and relatedness patterns here (10pt)\n\nLinks\n\nYou can borrow code from the lecture and the links below\n\nhttps://hakyimlab.github.io/hgen471/L6-population-structure.html\nhttps://bios25328.hakyimlab.org/post/2020/02/06/l8-grm/\n\nslides\n\n\nThe following code will directly download the bed/bim/fam files\nwget -O hapmap3_ch22.bed https://uchicago.box.com/shared/static/uu5fbx135qgp37spnrrsxrk4acuibkwh.bed\nwget -O hapmap3_ch22.bim https://uchicago.box.com/shared/static/eh0thcbeo5sb1ywufrowtm3uqqgad0b2.bim\nwget -O hapmap3_ch22.fam https://uchicago.box.com/shared/static/7py9smo190ucl6jrdwe0de8wjdc6rrwq.fam\n\n\nHow to download plink\nwget https://s3.amazonaws.com/plink1-assets/plink_linux_x86_64_20220305.zip\n##Use this link if you are on Rstudio Cloud otherwise go to the website\n##https://zzz.bwh.harvard.edu/plink/download.shtml \nunzip plink_linux_x86_64_20220305.zip\nmikdir bin \nmv plink bin"
  },
  {
    "objectID": "post/bios-25328/2024-04-01-homework-03/index.html#c.-finish-running-the-marees-gwas-tutorial",
    "href": "post/bios-25328/2024-04-01-homework-03/index.html#c.-finish-running-the-marees-gwas-tutorial",
    "title": "homework 3",
    "section": "C. Finish running the Marees GWAS tutorial",
    "text": "C. Finish running the Marees GWAS tutorial\n\nFinish lab 3 and answer the following questions.\n\nUsing the output from the tutorial or using the commands you learned from it, answer the following questions. Show the command you used to create the result.\n\nHow many individuals are in the genotype file you downloaded? (5 pts)\nExplain the contents of .fam, .bim, .bed files (5 pts)\nWrite the captions for the figures generated by the commands in 1_Main_script_QC_GWAS.txt and 3_Main_script_association_GWAS (5 pts per figure caption)\nExplain what you accomplished with the tutorial and explain the results/figures you obtained. (20 pts)"
  },
  {
    "objectID": "post/bios-25328/2024-04-01-lecture-05/index.html",
    "href": "post/bios-25328/2024-04-01-lecture-05/index.html",
    "title": "lecture 5",
    "section": "",
    "text": "Lecture 5 slides link\n\n\n\n\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-03-25-homework-02/index.html",
    "href": "post/bios-25328/2024-03-25-homework-02/index.html",
    "title": "homework 2",
    "section": "",
    "text": "Lecture 3 assessment quiz (10 points)\nLecture 4 assessment quiz (10 points)\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-03-25-homework-02/index.html#complete-the-following",
    "href": "post/bios-25328/2024-03-25-homework-02/index.html#complete-the-following",
    "title": "homework 2",
    "section": "",
    "text": "Lecture 3 assessment quiz (10 points)\nLecture 4 assessment quiz (10 points)"
  },
  {
    "objectID": "post/bios-25328/2024-03-25-homework-02/index.html#multiple-testing-simulation-30-points",
    "href": "post/bios-25328/2024-03-25-homework-02/index.html#multiple-testing-simulation-30-points",
    "title": "homework 2",
    "section": "2. Multiple testing simulation (30 points)",
    "text": "2. Multiple testing simulation (30 points)\n\nSimulate X, Ynull, Yalt\nPlot Ynull vs X, Yalt vs X\nRun linear regression and find the estimated effect sizes\nRepeat the simulations 10000 times and save the coefficients and p-values for each simulation in vectors\nPlot the distribution of p-values when you use Ynull and Yalt\nSimulate a mixture of Ynull and Yalt using a vector (selectvec) that determines whether the null or alternative is the true model\nShow the distribution of p-values using the histogram. Also try using qqplot of the p-values and simulated uniform random variables (show the identity line). Interpret the figure.\nFor your simulation, calculate the entries of the “confusion table”, i.e. the one that has the number of significant, not significant, discriminated by whether they are real or not (slide page 29)\nIn a real data analysis, can you calculate this table? Why yes or not?\nInstall the qvalue package and calculate the qvalues for your pvalues\nCalculate the pi0 from the qvalue results. How does it compare to the proportion of null Y’s you simulated? Interpret.\n\nHint: use the code from the lecture slides or here\n\nextra credit: simulate X as a more realistic genotype using maf of 0.3\nextra extra credit: simulate a binary trait using the logistic regression vignette we saw in class"
  },
  {
    "objectID": "post/bios-25328/2024-04-12-homework-04/index.html",
    "href": "post/bios-25328/2024-04-12-homework-04/index.html",
    "title": "homework 4",
    "section": "",
    "text": "Lecture 7 assessment quiz (10 points)\nLecture 8 assessment quiz (10 points)\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2024-04-12-homework-04/index.html#a.-complete-the-following-assessments",
    "href": "post/bios-25328/2024-04-12-homework-04/index.html#a.-complete-the-following-assessments",
    "title": "homework 4",
    "section": "",
    "text": "Lecture 7 assessment quiz (10 points)\nLecture 8 assessment quiz (10 points)"
  },
  {
    "objectID": "post/bios-25328/2024-04-12-homework-04/index.html#b.-finish-the-knit-lab-4-40-points",
    "href": "post/bios-25328/2024-04-12-homework-04/index.html#b.-finish-the-knit-lab-4-40-points",
    "title": "homework 4",
    "section": "B. Finish the knit lab 4 (40 points)",
    "text": "B. Finish the knit lab 4 (40 points)"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html",
    "title": "Transcriptome QGT Training 2024",
    "section": "",
    "text": "NEEDS UPDATE\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-01",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-01",
    "title": "Transcriptome QGT Training 2024",
    "section": "Questionnaire 01",
    "text": "Questionnaire 01\n\nOpen and start filling questionnaire 01 Preliminary questionnaire https://forms.gle/fhNJAyjx7MJTy3yt8\nInstall packages as needed\n\n\n# List of packages you want to install\npackages &lt;- c(\"tidyverse\", \"data.table\", \"BEDMatrix\", \"Rfast\", \"susieR\", \"coloc\")\n\n# Function to check and install any missing packages\ncheck_and_install &lt;- function(pkg){\n  if (!require(pkg, character.only = TRUE)) {\n    install.packages(pkg, dependencies = TRUE)\n    library(pkg, character.only = TRUE)\n  }\n}\n\n# Use the function to check and install packages\nsapply(packages, check_and_install)\n\n\nLoad Rstudio Libraries\n\n\nlibrary(tidyverse)\n\n## packages needed for susie+coloc\nlibrary(data.table)\nlibrary(BEDMatrix)\nlibrary(Rfast)\nlibrary(susieR)\nlibrary(coloc)\n##library(tidyverse)\n\n\nNavigate to starting directory\n\n\ncd \"/cloud/project/\"\n\n\nactivate the the imlabtools environment, which will make sure that the right version of python modules are available\n\n\nconda activate imlabtools\n\n\nTo define some variables to access the data more easily within the R session, run the following r chunk\n\n\nprint(getwd())\n\nlab=\"/cloud/project/QGT-Columbia-HKI-repo/\"\nCODE=glue::glue(\"{lab}/code\")\nsource(glue::glue(\"{CODE}/load_data_functions.R\"))\nsource(glue::glue(\"{CODE}/plotting_utils_functions.R\"))\n\nPRE=\"/cloud/project/QGT-Columbia-HKI-repo/box_files\"\nMODEL=glue::glue(\"{PRE}/models\")\nDATA=glue::glue(\"{PRE}/data\")\nRESULTS=glue::glue(\"{PRE}/results\")\nMETAXCAN=glue::glue(\"{PRE}/repos/MetaXcan-master/software\")\nFASTENLOC=glue::glue(\"{PRE}/repos/fastenloc-master\")\n\n# This is a reference table we'll use a lot throughout the lab. It contains information about the genes.\ngencode_df = load_gencode_df()\n\n\ncheck the values of the variables you just defined in R\n\n\nMODEL\n\nDATA\n\n\ndefine some variables to access the data more easily in the terminal. Remember we are running R code in the R console and command line code in the terminal.\n\n\nexport PRE=\"/cloud/project/QGT-Columbia-HKI-repo/box_files\"\nexport LAB=\"/cloud/project/QGT-Columbia-HKI-repo/\"\nexport CODE=$LAB/code\nexport DATA=$PRE/data\nexport MODEL=$PRE/models\nexport RESULTS=$PRE/results\nexport METAXCAN=$PRE/repos/MetaXcan-master/software\n\n\ncheck the values of the variables you just defined\n\n\n\necho $CODE\necho $RESULTS"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-02",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-02",
    "title": "Transcriptome QGT Training 2024",
    "section": "Questionnaire 02",
    "text": "Questionnaire 02\n\nOpen and start filling questionnaire 02 Prediction https://forms.gle/T6kAHvFTxYfcQguW7"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#optional-assess-actual-prediction-performance",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#optional-assess-actual-prediction-performance",
    "title": "Transcriptome QGT Training 2024",
    "section": "(Optional) Assess Actual Prediction Performance",
    "text": "(Optional) Assess Actual Prediction Performance\n\n## download and read observed expression data from GEUVADIS \n## from https://uchicago.box.com/s/4y7xle5l0pnq9d1fwmthe2ewhogrnlrv\n\nobs_exp&lt;- read_csv(glue::glue(\"{DATA}/predixcan/GEUVADIS.observed_df.csv.gz\"))\n\n## Note that the version of the ensemble id of the gene was removed\nhead(predicted_expression)\n\n## Q: how many genes were predicted?\nlength(unique(predicted_expression$gene_id))\n\n## inner join predicted expression with observed expression data (by IID and gene)\n## common errors occur when ensemble id's have versions in one set and not the other set\nfullset=inner_join(predicted_expression, obs_exp, by = c(\"gene_id\",\"IID\"))\n\n## calculate spearman correlation for all genes\ngenelist = unique(predicted_expression$gene_id)\ncorvec = rep(NA,length(genelist))\nnames(corvec) = genelist\nfor(gg in 1:length(genelist))\n{\n  ind = fullset$gene_id==genelist[gg]\n  corvec[gg] = cor(fullset$predicted_expression[ind], fullset$observed_expression[ind])\n}\n\n## what's the best performing gene?\n\n## plot the histogram of the prediction performance\nhist(corvec)\n\n## list the top 10 best performing genes\nhead(sort(corvec,decreasing = TRUE),2)\ntail(sort(corvec,decreasing = TRUE),2)\n\n## plot the correlation of the top 2 best performing genes bottom 2\n\ngeneid = \"ENSG00000100376\"\ngenename = gencode_df %&gt;% filter(gene_id==geneid) %&gt;% .[[\"gene_name\"]]\nfullset %&gt;% filter(gene_id==geneid) %&gt;% ggplot(aes(observed_expression, predicted_expression))+geom_point()+ggtitle(paste(genename, \"-\",geneid))\n\ngeneid = \"ENSG00000075234\"\ngenename = gencode_df %&gt;% filter(gene_id==geneid) %&gt;% .[[\"gene_name\"]]\nfullset %&gt;% filter(gene_id==geneid) %&gt;% ggplot(aes(observed_expression, predicted_expression))+geom_point()+ggtitle(paste(genename, \"-\", geneid))\n\ngeneid = \"ENSG00000070371\"\ngenename = gencode_df %&gt;% filter(gene_id==geneid) %&gt;% .[[\"gene_name\"]]\nfullset %&gt;% filter(gene_id==geneid) %&gt;% ggplot(aes(observed_expression, predicted_expression))+geom_point()+ggtitle(paste(genename, \"-\", geneid))\n\ngeneid = \"ENSG00000184164\"\ngenename = gencode_df %&gt;% filter(gene_id==geneid) %&gt;% .[[\"gene_name\"]]\nfullset %&gt;% filter(gene_id==geneid) %&gt;% ggplot(aes(observed_expression, predicted_expression))+geom_point()+ggtitle(paste(genename, \"-\", geneid))"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-03",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-03",
    "title": "Transcriptome QGT Training 2024",
    "section": "Questionnaire 03",
    "text": "Questionnaire 03\n\nOpen and start filling questionnaire 03 PrediXcan https://forms.gle/3H319knWbLgnynNs9\n\nWe are going to use a simulated phenotype for which only UPK3A has an effect on the phenotype (\\(\\beta=-0.9887378\\))\n\\(Y = \\sum_k T_k \\beta_k + \\epsilon\\)\nwith random effects \\(\\beta_k \\sim (1-\\pi)\\cdot \\delta_0 + \\pi\\cdot N(0,1)\\)\n\n\nexport PHENO=\"sim.spike_n_slab_0.01_pve0.1\"\n\nprintf \"association\\n\\n\"\npython3 $METAXCAN/PrediXcanAssociation.py \\\n--expression_file $RESULTS/predixcan/Whole_Blood__predict.txt \\\n--input_phenos_file $DATA/predixcan/phenotype/$PHENO.txt \\\n--input_phenos_column pheno \\\n--output $RESULTS/predixcan/$PHENO/Whole_Blood__association.txt \\\n--verbosity 9 \\\n--throw\n\nMore predicted phenotypes can be found in $DATA/predixcan/phenotype/. The naming of the phenotypes provides information about the genetic architecture: the number after pve is the proportion of variance of Y explained by the genetic component of expression. The number after spike_n_slab represents the probability that a gene is causal π (i.e. prob β≠0)"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#looking-at-association-results",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#looking-at-association-results",
    "title": "Transcriptome QGT Training 2024",
    "section": "Looking at Association Results",
    "text": "Looking at Association Results\n\n## read association results\nPHENO=\"sim.spike_n_slab_0.01_pve0.1\"\n\npredixcan_association = load_predixcan_association(glue::glue(\"{RESULTS}/predixcan/{PHENO}/Whole_Blood__association.txt\"), gencode_df)\n\n## take a look at the results\ndim(predixcan_association)\npredixcan_association %&gt;% arrange(pvalue) %&gt;% select(gene_name,effect,se,pvalue,gene) %&gt;% head\npredixcan_association %&gt;% arrange(pvalue) %&gt;% ggplot(aes(pvalue)) + geom_histogram(bins=10)\n## compare distribution against the null (uniform)\ngg_qqplot(predixcan_association$pvalue, max_yval = 40)"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#comparing-the-estimated-effect-size-with-true-effect-size",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#comparing-the-estimated-effect-size-with-true-effect-size",
    "title": "Transcriptome QGT Training 2024",
    "section": "Comparing the Estimated Effect Size with True Effect Size",
    "text": "Comparing the Estimated Effect Size with True Effect Size\n\ntruebetas = load_truebetas(glue::glue(\"{DATA}/predixcan/phenotype/gene-effects/{PHENO}.txt\"), gencode_df)\nbetas = (predixcan_association %&gt;% \n               inner_join(truebetas,by=c(\"gene\"=\"gene_id\")) %&gt;%\n               select(c('estimated_beta'='effect', \n                        'true_beta'='effect_size',\n                        'pvalue', \n                        'gene_id'='gene', \n                        'gene_name'='gene_name.x', \n                        'region_id'='region_id.x')))\nbetas %&gt;% arrange(pvalue) %&gt;% select(gene_name,estimated_beta,true_beta,pvalue) %&gt;% head\n## do you see examples of potential LD contamination?\nbetas %&gt;% mutate(causal= true_beta!=0) %&gt;% ggplot(aes(estimated_beta, true_beta,col=causal))+geom_point(alpha=0.6,size=5)+geom_abline()+theme_bw()\n\n\nUPK3A is the causal gene and has the most significant pvalue. RIBC2 is also significantly associated but has no causal role (we know because we simulated the phenotype that way). Why?\n\nHint: correlation between the genes"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-04",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-04",
    "title": "Transcriptome QGT Training 2024",
    "section": "Questionnaire 04",
    "text": "Questionnaire 04\n\nOpen and start filling questionnaire 04 S-PrediXcan https://forms.gle/xJs2U66cnrqdb5cj6"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#running-s-predixcan",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#running-s-predixcan",
    "title": "Transcriptome QGT Training 2024",
    "section": "Running S-PrediXcan",
    "text": "Running S-PrediXcan\n\n\npython $METAXCAN/SPrediXcan.py \\\n--gwas_file  $DATA/spredixcan/imputed_CARDIoGRAM_C4D_CAD_ADDITIVE.txt.gz \\\n--snp_column panel_variant_id \\\n--effect_allele_column effect_allele \\\n--non_effect_allele_column non_effect_allele \\\n--zscore_column zscore \\\n--model_db_path $MODEL/gtex_v8_mashr/mashr_Whole_Blood.db \\\n--covariance $MODEL/gtex_v8_mashr/mashr_Whole_Blood.txt.gz \\\n--keep_non_rsid \\\n--additional_output \\\n--model_db_snp_key varID \\\n--throw \\\n--output_file $RESULTS/spredixcan/eqtl/CARDIoGRAM_C4D_CAD_ADDITIVE__PM__Whole_Blood.csv\n\n\nWe can run the full genome because the summary statistics based PrediXcan is much faster than individual level one."
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#plot-and-interpret-results",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#plot-and-interpret-results",
    "title": "Transcriptome QGT Training 2024",
    "section": "Plot and Interpret Results",
    "text": "Plot and Interpret Results\n\nspredixcan_association = load_spredixcan_association(glue::glue(\"{RESULTS}/spredixcan/eqtl/CARDIoGRAM_C4D_CAD_ADDITIVE__PM__Whole_Blood.csv\"), gencode_df)\ndim(spredixcan_association)\nspredixcan_association %&gt;% arrange(pvalue) %&gt;% head\nspredixcan_association %&gt;% arrange(pvalue) %&gt;% ggplot(aes(pvalue)) + geom_histogram(bins=20)\n\ngg_qqplot(spredixcan_association$pvalue)\n\n\nQuestion: SORT1, considered to be a causal gene for LDL cholesterol and as a consequence of coronary artery disease, is not found here. Why?\ncheck whether SORT1 is expressed in whole blood GTEx portal\ncheck whether SORT1 has eQTL in whole blood GTEx portal"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#run-s-predixcan-using-gene-expression-predicted-in-liver",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#run-s-predixcan-using-gene-expression-predicted-in-liver",
    "title": "Transcriptome QGT Training 2024",
    "section": "Run S-PrediXcan using gene expression predicted in liver",
    "text": "Run S-PrediXcan using gene expression predicted in liver\n-[] Run s-predixcan with liver model, do you find SORT1? Is it significant?\n\n#loction Liver models \n#/cloud/project/QGT-Columbia-HKI-repo/box_files/models/gtex_v8_mashr/\npython $METAXCAN/SPrediXcan.py \\\n--gwas_file  $DATA/spredixcan/imputed_CARDIoGRAM_C4D_CAD_ADDITIVE.txt.gz \\\n--snp_column panel_variant_id \\\n--effect_allele_column effect_allele \\\n--non_effect_allele_column non_effect_allele \\\n--zscore_column zscore \\\n--model_db_path $MODEL/gtex_v8_mashr/mashr_Liver.db \\\n--covariance $MODEL/gtex_v8_mashr/mashr_Liver.txt.gz \\\n--keep_non_rsid \\\n--additional_output \\\n--model_db_snp_key varID \\\n--throw \\\n--output_file $RESULTS/spredixcan/eqtl/CARDIoGRAM_C4D_CAD_ADDITIVE__PM__Liver.csv\n\n\nspredixcan_association_L= load_spredixcan_association(glue::glue(\"{RESULTS}/spredixcan/eqtl/CARDIoGRAM_C4D_CAD_ADDITIVE__PM__Liver.csv\"), gencode_df)\ndim(spredixcan_association_L)\nspredixcan_association_L %&gt;% arrange(pvalue) %&gt;% head\nspredixcan_association_L %&gt;% arrange(pvalue) %&gt;% ggplot(aes(pvalue)) + geom_histogram(bins=20)\n\ngg_qqplot(spredixcan_association_L$pvalue)\ncol_order= c(\"gene_name\",\"gene\",\"zscore\",\"effect_size\",\"pvalue\",\"var_g\",\"pred_perf_r2\", \"pred_perf_pval\",\"pred_perf_qval\", \"n_snps_used\", \"n_snps_in_cov\", \"n_snps_in_model\",\"best_gwas_p\",\"largest_weight\")\nspredixcan_association_L &lt;- spredixcan_association_L[, col_order]\nfilter(spredixcan_association_L, gene_name==\"SORT1\")"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#optional-compare-zscores-in-liver-and-whole-blood.",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#optional-compare-zscores-in-liver-and-whole-blood.",
    "title": "Transcriptome QGT Training 2024",
    "section": "(Optional) Compare zscores in liver and whole blood.",
    "text": "(Optional) Compare zscores in liver and whole blood.\n\nRecall that zscore is the effect size divided by the standard error\n\n\nspredixcan_association_L=rename(spredixcan_association_L, zscore_liver = \"zscore\")\nhead(spredixcan_association_L)\ntest=left_join(spredixcan_association, spredixcan_association_L, by=\"gene_name\")\ntest=select(test,\"gene_name\",\"zscore\",\"zscore_liver\")\ntest %&gt;% arrange(zscore_liver) %&gt;% head\n\ntest %&gt;% mutate(zscore_WB=zscore) %&gt;% ggplot(aes(zscore_WB,zscore_liver)) + geom_point(size=3,alpha=.6) + geom_abline()\n\n## S-PrediXcan association in liver and whole blood are significantly correlated\ncor.test(test$zscore,test$zscore_liver)"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#optional-run-multixcan",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#optional-run-multixcan",
    "title": "Transcriptome QGT Training 2024",
    "section": "(Optional) Run MultiXcan",
    "text": "(Optional) Run MultiXcan\n\nmultixcan aggregates information across multiple tissues to boost the power to detect association. It was developed movivated by the fact that eQTLs are shared across multiple tissues, i.e. many genetic variants that regulate expression are common across tissues.\nbefore you run multixcan ensure you have run s-predixcan for all the tissues you want to multixcan. In this tutorial we have two tissues (liver and whole blood), ensure you have run s-predixcan with the two tissues before running multixcan.\nOne thing to note is to ensure similar naming pattern for the output files. This is to ensure the files are captured correctly when running multixcan’s filter.\n\n\n\npython $METAXCAN/SMulTiXcan.py \\\n--models_folder $MODEL/gtex_v8_mashr \\\n--models_name_pattern \"mashr_(.*).db\" \\\n--snp_covariance $MODEL/gtex_v8_expression_mashr_snp_smultixcan_covariance.txt.gz \\\n--metaxcan_folder $RESULTS/spredixcan/eqtl/ \\\n--metaxcan_filter \"CARDIoGRAM_C4D_CAD_ADDITIVE__PM__(.*).csv\" \\\n--metaxcan_file_name_parse_pattern \"(.*)__PM__(.*).csv\" \\\n--gwas_file $DATA/spredixcan/imputed_CARDIoGRAM_C4D_CAD_ADDITIVE.txt.gz \\\n--snp_column panel_variant_id --effect_allele_column effect_allele --non_effect_allele_column non_effect_allele --zscore_column zscore --keep_non_rsid --model_db_snp_key varID \\\n--cutoff_condition_number 30 \\\n--verbosity 9 \\\n--throw \\\n--output $RESULTS/smultixcan/eqtl/CARDIoGRAM_C4D_CAD_ADDITIVE_smultixcan.txt"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-5",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-5",
    "title": "Transcriptome QGT Training 2024",
    "section": "Questionnaire 5",
    "text": "Questionnaire 5\n\nOpen and start filling questionnaire 05 Colocalization https://forms.gle/NfH2MSdy4UyJzGAp7"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#run-colocalization",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#run-colocalization",
    "title": "Transcriptome QGT Training 2024",
    "section": "Run colocalization",
    "text": "Run colocalization\nWhen you use coloc on your own data, you may want to check out coloc’s documentation, with good advice and tips on avoiding common mistakes https://cran.r-project.org/web/packages/coloc/vignettes\nDue to time constraints, we will run one region and one gene only\n\nFinemap GWAS of CAD\nFinemap eQTL of SORT1\n\nFor finemapping, we need the summary statistics (effect size, standard errors, etc) and the correlation between SNPs (LD matrix)"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#load-the-genotype-to-calculate-the-ld-matrix",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#load-the-genotype-to-calculate-the-ld-matrix",
    "title": "Transcriptome QGT Training 2024",
    "section": "load the genotype to calculate the ld matrix",
    "text": "load the genotype to calculate the ld matrix\n\n# load the genotype to calculate the ld matrix\nX_mat &lt;- BEDMatrix(glue::glue(\"{DATA}/colocalization/geuvadis_chr1\"))\ncolnames(X_mat) &lt;- gsub(\"\\\\_.*\", \"\",colnames(X_mat))\ncolnames(X_mat) &lt;- str_replace_all(colnames(X_mat),\":\",\"_\")\nsnp_info &lt;- fread(glue::glue(\"{DATA}/colocalization/geuvadis_chr1.bim\")) %&gt;% \n  setnames(., colnames(.), c(\"chr\", \"snp\", \"cm\", \"pos\", \"alt\", \"ref\")) \n\nsnp_info$snp &lt;- str_replace_all(snp_info$snp,\":\",\"_\")"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#load-the-eqtl-and-gwas-effect-size-files",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#load-the-eqtl-and-gwas-effect-size-files",
    "title": "Transcriptome QGT Training 2024",
    "section": "Load the eqtl and gwas effect size files",
    "text": "Load the eqtl and gwas effect size files\n\n# load the eqtl effect sizes\ngene_ss &lt;- fread(glue::glue(\"{DATA}/colocalization/Liver_chr1.txt\"))\n\n# load gwas effect sizes\ngwas &lt;- data.table::fread(glue::glue(\"{DATA}/spredixcan/imputed_CARDIoGRAM_C4D_CAD_ADDITIVE.txt.gz\"))\n\n# filter to select genome wide significant snps at 5 × 10−8\nfiltered_regions &lt;- gwas %&gt;% dplyr::filter(pvalue &lt; 5e-8)\n\n# load the ld block\nldblocks &lt;-read_tsv(glue::glue(\"{DATA}/spredixcan/eur_ld.hg38.txt.gz\"))"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#find-regions-with-the-strongest-signal-in-the-gwas",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#find-regions-with-the-strongest-signal-in-the-gwas",
    "title": "Transcriptome QGT Training 2024",
    "section": "Find regions with the strongest signal in the gwas",
    "text": "Find regions with the strongest signal in the gwas\n\n# get the loci where the significant snps are located\nfor (n in 1:nrow(filtered_regions)){\n  # extract genename, start and end\n  variant_id &lt;- as.character(filtered_regions[n,\"variant_id\"])\n  variant_chr &lt;- as.character(filtered_regions[n,\"chromosome\"])\n  variant_pos &lt;- as.numeric(filtered_regions[n,\"position\"])\n  #gene_end &lt;- as.numeric(genes[n,\"end\"])\n\n  locus &lt;- ldblocks %&gt;%\n    dplyr::filter(chr == variant_chr) %&gt;%\n    filter(variant_pos &gt;= start & variant_pos &lt; stop) %&gt;%\n    mutate(locus_name = paste0(chr,\"_\",start,\"_\",stop)) %&gt;%\n    dplyr::rename(locus_start=start,locus_end=stop) %&gt;%\n    mutate(variant_id = variant_id, position=variant_pos)\n\n  # create a data frame with info\n  if (exists('all_loci') && is.data.frame(get('all_loci'))) {\n    all_loci &lt;- rbind(all_loci,locus)\n  } else {\n    all_loci &lt;- locus\n  }\n}\n\n# select uniq loci\nd_loci &lt;- all_loci %&gt;%\n  dplyr::select(locus_name,chr,locus_start,locus_end) %&gt;%\n  dplyr::distinct()"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#select-a-region-to-run-coloc",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#select-a-region-to-run-coloc",
    "title": "Transcriptome QGT Training 2024",
    "section": "select a region to run coloc",
    "text": "select a region to run coloc\n\n# select regions to fine map. we are going to use regions in chromosome 1\nuniq_loci &lt;- d_loci %&gt;% dplyr::filter(\"chr1\" == chr)\nn = 3 # chr1_107867043_109761309 region\n\n# extract information\nl_chr = as.numeric(str_remove(uniq_loci[n,\"chr\"],\"chr\"))\ns_chr = uniq_loci[n,]$chr\nl_start = uniq_loci[n,]$locus_start\nl_stop = uniq_loci[n,]$locus_end\nl_name = uniq_loci[n,]$locus_name"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#prepare-gwas-data-for-coloc",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#prepare-gwas-data-for-coloc",
    "title": "Transcriptome QGT Training 2024",
    "section": "Prepare gwas data for coloc",
    "text": "Prepare gwas data for coloc\n\n# select snps for the region from the summary stats\nss &lt;- gwas %&gt;% \n  dplyr::filter(chromosome == s_chr) %&gt;%\n  dplyr::filter(position &gt;= l_start & position &lt;= l_stop) %&gt;% \n  dplyr::filter(! is.na(effect_size))\n\n# find the snps in the genotype to calculate the correlation\ng.snps &lt;- ss %&gt;% inner_join(snp_info %&gt;% mutate(chr = glue::glue(\"chr{chr}\")), \n                            by=c(\"chromosome\" = \"chr\",\"panel_variant_id\" = \"snp\"))\n\n\n# select genotype to calculate correlation\n#f_mat &lt;- X_mat[,g.snps$snp]\nf_mat &lt;- X_mat[,g.snps$panel_variant_id]\n\n# calculate corr\nR = cora(f_mat) # the package is for speed\n\n## clean up\nrm(f_mat)\n\nff &lt;- g.snps %&gt;% dplyr::filter(! is.na(effect_size)) %&gt;% #select(-snp) %&gt;% \n  dplyr::rename(snp=panel_variant_id,beta=effect_size) %&gt;% \n  mutate(varbeta = standard_error^2) %&gt;% \n  dplyr::select(beta,varbeta,snp,position) %&gt;% as.list()\n\nff$type &lt;- \"cc\"\nff$sdY &lt;- 1\n\nff$LD = R\nff$N = 184305\n\n## check the data (NULL means it's fine)\ncheck_dataset(ff)"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#prepare-eqtl-data-for-coloc",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#prepare-eqtl-data-for-coloc",
    "title": "Transcriptome QGT Training 2024",
    "section": "Prepare eqtl data for coloc",
    "text": "Prepare eqtl data for coloc\n\n#Using SORT1 gene and liver tissue\ngene &lt;- gene_ss %&gt;% dplyr::filter(gene_id == \"ENSG00000134243.11\") %&gt;% \n  dplyr::rename(snp = variant_id,beta = slope, MAF = maf,\n                pvalue = pval_nominal) %&gt;% \n  mutate(varbeta = slope_se^2, name = snp) %&gt;% \n  filter(! is.na(varbeta)) %&gt;% \n  separate(name, into = c(\"chr\", \"position\",\"ref\",\"alt\",\"build\"),sep = \"_\")\n\n## calculate the ld matrix\n### get the snps\ngene.snps &lt;- gene %&gt;% mutate(position = as.integer(position)) %&gt;% \n  inner_join(snp_info %&gt;% mutate(chr = glue::glue(\"chr{chr}\")), \n                              by=c(\"chr\" = \"chr\",\"snp\" = \"snp\"))\n\n# select genotype to calculate correlation\ng_mat &lt;- X_mat[,gene.snps$snp]\n# calculate corr\ng.R = cora(g_mat)\n\n# clean up\nrm(g_mat)\n\n# format data for coloc\ngg &lt;- gene %&gt;% dplyr::filter(snp %in% gene.snps$snp) %&gt;%\n  mutate(position = as.integer(position)) %&gt;% \n  dplyr::select(beta,varbeta,snp,position,MAF, pvalue) %&gt;% as.list()\n\ngg$type &lt;- \"quant\"\ngg$LD = g.R\ngg$N = 208 # 670 for blood\n\n## check the data\ncheck_dataset(gg)"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#run-older-version-of-coloc-which-assumes-single-causal-variant",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#run-older-version-of-coloc-which-assumes-single-causal-variant",
    "title": "Transcriptome QGT Training 2024",
    "section": "run older version of coloc which assumes single causal variant",
    "text": "run older version of coloc which assumes single causal variant\ncoloc.abf makes the simplifying assumption that each trait has at most one causal variant in the region under consideration\n\nmy.res &lt;- coloc.abf(dataset1=ff, dataset2=gg)\nsensitivity(my.res,\"H4 &gt; 0.9\")"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#run-coloc-allowing-multiple-causal-variants",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#run-coloc-allowing-multiple-causal-variants",
    "title": "Transcriptome QGT Training 2024",
    "section": "run coloc allowing multiple causal variants",
    "text": "run coloc allowing multiple causal variants\nMultiple causal variants, using SuSiE to separate the signals\n\n# Run susie fine maooing\nS3 = runsusie(ff)\nS4 = runsusie(gg)\n#summary(S3)\n\n# Run coloc\nsusie.res=coloc.susie(S3,S4)\nprint(susie.res$summary)\n\nSuSiE can take a while to run on larger datasets, so it is best to run once per dataset with the =runsusie= function, store the results and feed those into subsequent analyses.\nplot the coloc result with the sensitivity function because weird effects are much easier to understand visually\n\nsensitivity(susie.res,\"H4 &gt; 0.9\",row=1,dataset1=ff,dataset2=gg,)"
  },
  {
    "objectID": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-06",
    "href": "post/qgt/2024-06-24-QGT-workbook/index.html#questionnaire-06",
    "title": "Transcriptome QGT Training 2024",
    "section": "Questionnaire 06",
    "text": "Questionnaire 06\n\nOpen and start filling out questionnaire 06 cTWAS https://forms.gle/A4evWkbhR7cXLy36A\n\n\n#install.packages(\"R.utils\")\n\n#install.packages(\"remotes\")\n#remotes::install_github(\"simingz/ctwas\", ref = \"develop\")\n\nlibrary(ctwas)\n\n#get positions for region of interest (SORT1/PSRC1 locus)\nregion &lt;- unlist(strsplit(spredixcan_association$region_id[spredixcan_association$gene_name==\"PSRC1\"], \"_\"))\nchr &lt;- region[2]\nstart &lt;- as.numeric(region[3])\nend &lt;- as.numeric(region[4])\n\n#format summary statistics (and subset to variants in region to save memory)\nz_snp &lt;- data.table::fread(glue::glue(\"{DATA}/spredixcan/imputed_CARDIoGRAM_C4D_CAD_ADDITIVE.txt.gz\"), select=c(\"chromosome\", \"position\", \"variant_id\", \"effect_allele\", \"non_effect_allele\", \"zscore\", \"sample_size\"))\nz_snp &lt;- z_snp[z_snp$chromosome==chr & z_snp$position &gt;= start & z_snp$position &lt;= end,]\nz_snp &lt;- z_snp[!is.na(z_snp$variant_id),-(1:2)]\ncolnames(z_snp) &lt;- c(\"id\", \"A1\", \"A2\", \"z\", \"ss\")\n\n#specify directories for LD matrices and weights\nld_R_dir &lt;- glue::glue(\"{DATA}/cTWAS/LD_matrices\")\nweight &lt;-  glue::glue(\"{MODEL}/gtex_v8_mashr/mashr_Liver.db\")\n\n#specify output locations and names for cTWAS\noutputdir &lt;- glue::glue(\"{DATA}/cTWAS/results/\")\noutname.e &lt;- \"CARDIoGRAM_Liver_expr\"\noutname &lt;- \"CARDIoGRAM_Liver_ctwas\"\n\n#impute gene z scores using cTWAS and save the results\n##################################\n# NOTE: we are skipping this step and using the precomputed values \n## takes ~10 minutes\n##################################\n# ctwas_imputation &lt;- impute_expr_z(z_snp=z_snp, weight=weight, ld_R_dir=ld_R_dir, outputdir=outputdir, outname=outname.e, harmonize_z=F, harmonize_wgt=F)\n# save(ctwas_imputation, file = paste0(outputdir, outname.e, \"_output.Rd\"))\nload(paste0(outputdir, outname.e, \"_output.Rd\"))\n\nz_gene &lt;- ctwas_imputation$z_gene\nld_exprfs &lt;- ctwas_imputation$ld_exprfs\nz_snp &lt;- ctwas_imputation$z_snp\n\n#make custom region file for single region\nld_regions_custom &lt;- data.frame(\"chr\" = chr, \"start\" = start, \"stop\" = end)\n\nwrite.table(ld_regions_custom, \n            file= paste0(outputdir, \"ld_regions_custom.txt\"),\n            row.names=F, col.names=T, sep=\"\\t\", quote = F)\n    \nld_regions_custom &lt;- paste0(outputdir, \"ld_regions_custom.txt\")\n\n#run cTWAS with pre-specified prior parameters at a single locus\n#estimating prior requires genome-wide data, too slow for demonstration\n#prior is 1% inclusion for genes and is 100x more likely than SNPs\n#prior assumes genes have larger effect size than SNPs, in reasonable range for data we've looked at\nctwas_rss(z_gene=z_gene, z_snp=z_snp, ld_exprfs=ld_exprfs, ld_R_dir = ld_R_dir, ld_regions_custom=ld_regions_custom, outputdir = outputdir, outname = outname, thin = 0.01,\n          estimate_group_prior = F,\n          estimate_group_prior_var = F,\n          group_prior=c(0.01, 0.0001),\n          group_prior_var=c(50, 25))\n\n#load results\nctwas_results &lt;- data.table::fread(paste0(outputdir,outname,\".susieIrss.txt\"))\n\n#merge gene names into the results\nsqlite &lt;- RSQLite::dbDriver(\"SQLite\")\ndb = RSQLite::dbConnect(sqlite, weight)\nquery &lt;- function(...) RSQLite::dbGetQuery(db, ...)\nextra_table &lt;- query(\"select * from extra\")\nRSQLite::dbDisconnect(db)\n\nctwas_results$genename &lt;- extra_table$genename[match(ctwas_results$id, extra_table$gene)]\n\n#show results with highest PIPs\ncol_order_2= c(\"genename\", \"chrom\", \"id\", \"pos\", \"type\", \"region_tag1\", \"region_tag2\", \"cs_index\", \"susie_pip\" , \"mu2\")\nctwas_results &lt;- ctwas_results[, ..col_order_2]\nhead(ctwas_results[order(-ctwas_results$susie_pip),])"
  },
  {
    "objectID": "post/logistics/2024-03-19-course-checklist/index.html",
    "href": "post/logistics/2024-03-19-course-checklist/index.html",
    "title": "course checklist",
    "section": "",
    "text": "course checklist\nthree months prior\n\nidentify a TA for the course\n\ntwo weeks prior\n\nupdate the syllabus (copy the one from the previous year and make necessary changes, new dates, topics, etc)\n\none week prior\n\ndownload the class roster from facultyaccess page link\nsend welcome email (optional)\ncheck assigned classroom (edit syllabus as needed)\ncreate canvas for the course follow link under “how to create an organization site in Canvas” or try direct link canvas creation link\ndon’t forget to publish the canvas\nadd TA and intructors to canvas\nupdate slack channel\n\ncancer genetics and genomics slack\n\n\nfirst week\n\ncreate RCC account for students / or posit account\nset visibility of canvas to Institution during the first 2 weeks (shopping around period)\n\nafter two week set it to course\n\n\n\ntemplate email\n    Dear students, Welcome to the Cancer Genetics and Genomics course (BIOS-25328)! We are Lixing Yang, Haky Im, and Zach Weber and will be walking you through the course. Together, we will explore the current landscape of genetics and genomics of cancer. The field of genomics has made enormous progress over the last two decades, transforming the research of cancer and other diseases. We will survey the state of the art through literature review and hands-on analytical and computational exercises. We hope that by better understanding this devastating disease, we can help push the field forward and enable discoveries for prevention and treatment. In this journey, we will be working together, learning from each other, and supporting one another's success. The homework problems are not presented to you for scoring you but as intergral part of the learning process. If you do not understand what is asked, you are encouraged to ask questions. Our motto is that the only dumb questions are the ones that are not asked. You will get participation credit, regardless of whether your comments are right or not. You can find more detailed in formation in the canvas site ([https://canvas.uchicago.edu/courses/42065](https://canvas.uchicago.edu/courses/42065)) and the linked syllabus. We encourage you to join the slack channel and introduce yourselves. Tell us something fun or boring about yourselves. We look forward to seeing you in class. Lixing Yang, Zach Weber, and Haky Im\n    \n\n\n\n\n\n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hakyimlab Training Material Page",
    "section": "",
    "text": "Edit source here\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 2\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 4 - statistical significance in gwas - addressing multiple testing\n\n\n\n\n\n\nlecture\n\n\nbios25328\n\n\n\nLecture 4\n\n\n\n\n\nMar 31, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 4 - multiple testing correction - with code\n\n\n\n\n\n\nbios25328\n\n\nnotebook\n\n\n\nLecture 4\n\n\n\n\n\nMar 31, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 1\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nMar 31, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 3\n\n\n\n\n\n\nlecture\n\n\nbios25328\n\n\n\nLecture 3\n\n\n\n\n\nMar 31, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 2\n\n\n\n\n\n\nlecture\n\n\nbios25328\n\n\n\nLecture 2: Cancer GWAS\n\n\n\n\n\nMar 26, 2025\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nquick training in statistical genetics\n\n\n\n\n\nmaterial for introduction to statistical genetics\n\n\n\n\n\nJun 25, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome QGT Training 2024\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 5\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nApr 19, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlab 4\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2024\n\n\nLiz Gibbons\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 4\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nApr 12, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 8\n\n\n\n\n\n\nbios25328\n\n\nlecture\n\n\n\n\n\n\n\n\n\nApr 10, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 7\n\n\n\n\n\n\nbios25328\n\n\nlecture\n\n\n\n\n\n\n\n\n\nApr 8, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlab 3\n\n\n\n\n\n\nbios25328\n\n\nlab\n\n\n\nIn this lab, you will run all the steps of a GWAS analysis using the Marees et al tutorial.\n\n\n\n\n\nApr 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 3\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nApr 5, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 6\n\n\n\n\n\n\nbios25328\n\n\nlecture\n\n\n\n\n\n\n\n\n\nApr 3, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 5\n\n\n\n\n\n\nbios25328\n\n\nlecture\n\n\n\n\n\n\n\n\n\nApr 1, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlab 2\n\n\n\n\n\n\nbios25328\n\n\nlab\n\n\n\n\n\n\n\n\n\nMar 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 3\n\n\n\n\n\n\nbios25328\n\n\nlecture\n\n\n\n\n\n\n\n\n\nMar 25, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 2\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nMar 25, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nImages GWAS\n\n\n\n\n\n\n\n\n\n\n\nMar 24, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlecture 2\n\n\n\n\n\nDissection of Genetics & Prediction of Cancer Risk: Methods & Tools\n\n\n\n\n\nMar 20, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nlab 1 - command line and R\n\n\n\n\n\n\nbios25328\n\n\nlab\n\n\n\n\n\n\n\n\n\nMar 18, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nhomework 1\n\n\n\n\n\n\nbios25328\n\n\nhomework\n\n\n\n\n\n\n\n\n\nMar 18, 2024\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\ncourse checklist\n\n\n\n\n\n\nlogistics\n\n\n\n\n\n\n\n\n\nMar 19, 2023\n\n\nHaky Im\n\n\n\n\n\n\n\n\n\n\n\n\nLab Setup\n\n\n\n\n\n\n\n\n\n\n\nMay 6, 2022\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "",
    "text": "Find the lecture notes here.\n© HakyImLab and Listed Authors - CC BY 4.0 License"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#simulate-data-null-vs.-alternative",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#simulate-data-null-vs.-alternative",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Simulate Data: Null vs. Alternative",
    "text": "Simulate Data: Null vs. Alternative\nWe’ll start by simulating data under two scenarios:\n\nNull Hypothesis (Ynull): The outcome variable is independent of the predictor X.\nAlternative Hypothesis (Yalt): The outcome variable depends on the predictor X via the relationship Yalt = X * beta + epsilon."
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#simulation-parameters",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#simulation-parameters",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Simulation Parameters",
    "text": "Simulation Parameters\nFirst, define some parameters for the simulation.\n\n\nShow the code\n# Parameters\nnsamp = 100     # Number of samples\nbeta = 2        # Effect size for the alternative hypothesis\nh2 = 0.1        # Proportion of variance in Yalt explained by X (related to signal strength)\nsig2X = h2      # Variance of X (scaled for simplicity here)\nsig2epsi = (1 - h2) * beta^2 # Variance of the error term epsilon, ensuring desired h2\nsigX = sqrt(sig2X)\nsigepsi = sqrt(sig2epsi)\n\nprint(paste(\"Variance of X:\", sig2X))\n\n\n[1] \"Variance of X: 0.1\"\n\n\nShow the code\nprint(paste(\"Variance of Epsilon:\", sig2epsi))\n\n\n[1] \"Variance of Epsilon: 3.6\""
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#generate-single-instance-of-data",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#generate-single-instance-of-data",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Generate Single Instance of Data",
    "text": "Generate Single Instance of Data\nSimulate vectors X, epsilon (error), and Ynull (outcome under null). Then calculate Yalt.\n\n\nShow the code\n# Simulate predictor X and error term epsi\nX = rnorm(nsamp, mean=0, sd= sigX)\nepsi = rnorm(nsamp, mean=0, sd=sigepsi)\n\n# Generate Ynull (independent of X, here just sampling with variance related to beta for comparison)\nYnull = rnorm(nsamp, mean=0, sd=beta) \n\n# Calculate Yalt = X * beta + epsi\nYalt = X * beta + epsi"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#visualize-the-data",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#visualize-the-data",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Visualize the Data",
    "text": "Visualize the Data\n\n\nShow the code\n# Visualize Data\nplot(X, Yalt, main=\"Yalt vs X\"); grid()\n\n\n\n\n\n\n\n\n\nShow the code\nplot(X, Ynull, main=\"Ynull vs X\"); grid()"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#test-associations-single-instance",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#test-associations-single-instance",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Test Associations (Single Instance)",
    "text": "Test Associations (Single Instance)\nTest the association between Ynull and X using linear regression.\n\n\nShow the code\nsummary(lm(Ynull ~ X))\n\n\n\nCall:\nlm(formula = Ynull ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3548 -1.1589  0.0782  1.3735  4.6291 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  -0.0395     0.1951  -0.202    0.840\nX             1.0095     0.6240   1.618    0.109\n\nResidual standard error: 1.95 on 98 degrees of freedom\nMultiple R-squared:  0.02601,   Adjusted R-squared:  0.01607 \nF-statistic: 2.617 on 1 and 98 DF,  p-value: 0.1089\n\n\nQuestion: What is the p-value of the association between Ynull and X? Is it significant at the α=0.05 level?\nNow test the association between Yalt and X.\n\n\nShow the code\nsummary(lm(Yalt ~ X))\n\n\n\nCall:\nlm(formula = Yalt ~ X)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5453 -1.4809  0.1231  1.2189  4.1808 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  -0.4244     0.1891  -2.244   0.0271 * \nX             2.0521     0.6050   3.392   0.0010 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.89 on 98 degrees of freedom\nMultiple R-squared:  0.1051,    Adjusted R-squared:  0.09595 \nF-statistic: 11.51 on 1 and 98 DF,  p-value: 0.001001\n\n\nQuestion: What is the p-value of the association between Yalt and X? Is it significant at the α=0.05 level?"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#calculate-the-empirical-distribution-of-p-values",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#calculate-the-empirical-distribution-of-p-values",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Calculate the Empirical Distribution of P-values",
    "text": "Calculate the Empirical Distribution of P-values\nTo understand the distribution of p-values, we need to repeat the simulation many times.\n\nConvenience Function fastlm\nWe’ll run 10,000 regressions. A simplified function fastlm can speed this up compared to repeated calls to lm().\n\n\nShow the code\nfastlm = function(xx,yy) {\n  ## compute betahat (regression coef) and pvalue with Ftest\n  ## for now it does not take covariates\n  \n  df1 = 2 # DFs for model with predictor\n  df0 = 1 # DFs for null model (intercept only)\n  ind = !is.na(xx) & !is.na(yy)\n  xx = xx[ind]\n  yy = yy[ind]\n  n = sum(ind)\n  xbar = mean(xx)\n  ybar = mean(yy)\n  xx = xx - xbar # Center X\n  yy = yy - ybar # Center Y\n  \n  SXX = sum( xx^2 )\n  SYY = sum( yy^2 )\n  SXY = sum( xx * yy )\n  \n  betahat = SXY / SXX\n  \n  # RSS1 = Residual Sum of Squares for model Y ~ X\n  RSS1 = sum( ( yy - xx * betahat )^2 ) \n  # RSS0 = Residual Sum of Squares for model Y ~ 1 (equivalent to total sum of squares of centered Y)\n  RSS0 = SYY \n  \n  # F-statistic comparing the two models\n  fstat = ( ( RSS0 - RSS1 ) / ( df1 - df0 ) )  / ( RSS1 / ( n - df1 ) ) \n  # P-value from F-distribution\n  pval = 1 - pf(fstat, df1 = ( df1 - df0 ), df2 = ( n - df1 )) \n  \n  res = list(betahat = betahat, pval = pval)\n  return(res)\n}\n\n\n\n\nRun 10,000 Simulations\nSimulate X, Ynull, and Yalt 10,000 times. Store X and the outcomes in matrices.\n\n\nShow the code\nnsim = 10000 # Number of simulations\n\n# Simulate matrices: rows=samples, cols=simulations\nXmat = matrix(rnorm(nsim * nsamp, mean=0, sd= sigX), nsamp, nsim)\nepsimat = matrix(rnorm(nsim * nsamp, mean=0, sd=sigepsi), nsamp, nsim)\n\n# Generate Y matrices based on the formulas\nYmat_alt = Xmat * beta + epsimat \nYmat_null = matrix(rnorm(nsim * nsamp, mean=0, sd=beta), nsamp, nsim) # Null Ys\n\n# Check dimensions\ndim(Ymat_null)\n\n\n[1]   100 10000\n\n\nShow the code\ndim(Ymat_alt)\n\n\n[1]   100 10000\n\n\nShow the code\n# Assign column names for reference\ncolnames(Ymat_null) = paste0(\"sim\", 1:ncol(Ymat_null))\ncolnames(Ymat_alt) = colnames(Ymat_null)\n\n\n\n\nCalculate P-values Under the Null\nRun regressions for Ymat_null ~ Xmat for each simulation and store the p-values and coefficients.\n\n\nShow the code\npvec_null = rep(NA, nsim)\nbvec_null = rep(NA, nsim)\n\nfor(ss in 1:nsim) {\n  fit = fastlm(Xmat[,ss], Ymat_null[,ss])\n  pvec_null[ss] = fit$pval  \n  bvec_null[ss] = fit$betahat\n}\n\nsummary(pvec_null)\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0000021 0.2438476 0.4903663 0.4935828 0.7401156 0.9998408 \n\n\n\n\nShow the code\nhist(pvec_null, xlab=\"p-value\", main=\"Histogram of p-values under Null\", breaks=20)\n\n\n\n\n\n\n\n\n\nQuestions: - The histogram should look approximately uniform. Why? - How many simulations under the null yield p-value below 0.05? What percentage is that?\n\n\nShow the code\nsum(pvec_null &lt; 0.05)\n\n\n[1] 525\n\n\nShow the code\nmean(pvec_null &lt; 0.05)\n\n\n[1] 0.0525\n\n\nWhat proportion of simulations do you expect to have p-values &lt; α (for any α between 0 and 1) under the null? Why does this uniform distribution highlight the need for correction when performing many tests?"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#create-mixed-data",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#create-mixed-data",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Create Mixed Data",
    "text": "Create Mixed Data\nAssume a certain proportion (prop_alt) of our simulations represent true associations.\n\n\nShow the code\nprop_alt = 0.20 # Define proportion of alternative Ys in the mixture\n\n# Create a selection vector: 1 if alternative, 0 if null\nselectvec = rbinom(nsim, 1, prop_alt) \nnames(selectvec) = colnames(Ymat_alt) # Keep track\ntable(selectvec) # Show counts of null (0) vs alternative (1)\n\n\nselectvec\n   0    1 \n7996 2004 \n\n\nShow the code\n# Create the mixed Y matrix\n# If selectvec[i] is 1, use Ymat_alt[,i]; if 0, use Ymat_null[,i]\nYmat_mix = sweep(Ymat_alt, 2, selectvec, FUN='*') + sweep(Ymat_null, 2, 1 - selectvec, FUN='*')"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#calculate-p-values-for-mixed-data",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#calculate-p-values-for-mixed-data",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Calculate P-values for Mixed Data",
    "text": "Calculate P-values for Mixed Data\nRun regressions for Ymat_mix ~ Xmat.\n\n\nShow the code\npvec_mix = rep(NA, nsim)\nbvec_mix = rep(NA, nsim)\n\nfor(ss in 1:nsim) {\n  fit = fastlm(Xmat[,ss], Ymat_mix[,ss])\n  pvec_mix[ss] = fit$pval  \n  bvec_mix[ss] = fit$betahat\n}\n\nsummary(pvec_mix)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.07854 0.37313 0.40036 0.67907 0.99984 \n\n\n\n\nShow the code\nhist(pvec_mix, xlab=\"p-value\", main=\"Histogram of p-values under mixture\", breaks=20)"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#interpreting-mixed-p-values",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#interpreting-mixed-p-values",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Interpreting Mixed P-values",
    "text": "Interpreting Mixed P-values\nThe histogram shows a spike near zero (from true alternatives) superimposed on a uniform background (from true nulls).\n\n\nShow the code\nthres = 0.05\nm_signif = sum(pvec_mix &lt; thres)      # Observed number of significant associations\nm_expected_null = thres * sum(selectvec == 0) # Expected number of FPs from nulls\nm_expected_all_null = thres * nsim # Expected if *all* were null\n\nprint(paste(\"Observed significant (p&lt;0.05):\", m_signif))\n\n\n[1] \"Observed significant (p&lt;0.05): 2206\"\n\n\nShow the code\nprint(paste(\"Expected false positives if all were null:\", m_expected_all_null))\n\n\n[1] \"Expected false positives if all were null: 500\"\n\n\nShow the code\nprint(paste(\"Expected false positives from the actual nulls:\", round(m_expected_null)))\n\n\n[1] \"Expected false positives from the actual nulls: 400\"\n\n\nWe observed many more significant results than expected if all tests were null. How can we estimate the proportion of false discoveries among those we call significant?"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#false-discovery-rate-fdr-estimate-using-known-truth",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#false-discovery-rate-fdr-estimate-using-known-truth",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "False Discovery Rate (FDR) Estimate (using known truth)",
    "text": "False Discovery Rate (FDR) Estimate (using known truth)\nSince this is a simulation, we know which tests were truly null (selectvec == 0). We can calculate the actual FDR for a given p-value threshold.\n\n\nShow the code\n# FDR = (Number of significant tests that are truly null) / (Total number of significant tests)\nFP = sum(pvec_mix &lt; thres & selectvec == 0) # False Positives\nTP = sum(pvec_mix &lt; thres & selectvec == 1) # True Positives\nS = sum(pvec_mix &lt; thres) # Total Significant (S = FP + TP)\n\nFDR_sim = FP / S \nprint(paste(\"Simulated FDR at p &lt;\", thres, \":\", round(FDR_sim, 4)))\n\n\n[1] \"Simulated FDR at p &lt; 0.05 : 0.1886\"\n\n\nThis means that if we used p &lt; 0.05 as our criterion, about round(FDR_sim*100, 1)% of our significant findings would actually be false positives.\nQuestions: - What is the proportion of false discoveries (FDR) if we use a significance level of 0.01?\n\n\nShow the code\nthres_01 = 0.01\nFP_01 = sum(pvec_mix &lt; thres_01 & selectvec == 0)\nS_01 = sum(pvec_mix &lt; thres_01)\nFDR_sim_01 = FP_01 / S_01\nprint(paste(\"Simulated FDR at p &lt; 0.01:\", round(FDR_sim_01, 4)))\n\n\n[1] \"Simulated FDR at p &lt; 0.01: 0.0582\"\n\n\n\nWhat is the proportion of false discoveries if we use the Bonferroni threshold?\n\n\n\nShow the code\nFP_bf = sum(pvec_mix &lt; BF_thres & selectvec == 0)\nS_bf = sum(pvec_mix &lt; BF_thres)\nFDR_sim_bf = ifelse(S_bf &gt; 0, FP_bf / S_bf, 0) # Avoid division by zero\nprint(paste(\"Simulated FDR at Bonferroni p &lt;\", BF_thres, \":\", round(FDR_sim_bf, 4)))\n\n\n[1] \"Simulated FDR at Bonferroni p &lt; 5e-06 : 0.0055\"\n\n\nShow the code\nprint(paste(\"Number significant at Bonferroni:\", S_bf))\n\n\n[1] \"Number significant at Bonferroni: 181\"\n\n\n\nWhat is the proportion of missed signals (False Negative Rate among true alternatives) using the Bonferroni threshold?\n\n\n\nShow the code\nFN_bf = sum(pvec_mix &gt;= BF_thres & selectvec == 1) # False Negatives\nTotal_Alt = sum(selectvec == 1) # Total true alternatives\nFNR_sim_bf = FN_bf / Total_Alt\nprint(paste(\"Simulated FNR at Bonferroni p &lt;\", BF_thres, \":\", round(FNR_sim_bf, 4)))\n\n\n[1] \"Simulated FNR at Bonferroni p &lt; 5e-06 : 0.9102\""
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#table-of-simulation-results",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#table-of-simulation-results",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Table of Simulation Results",
    "text": "Table of Simulation Results\nLet’s construct the confusion table for our mixed simulation using alpha = 0.05.\n\n\nShow the code\ncount_table = t(table(Significant = pvec_mix &lt; 0.05, True_Status = selectvec))\n# Reorder and rename for standard confusion matrix format\n# Rows: True Status (0=Null, 1=Alt); Columns: Called Status (FALSE=Not Sig, TRUE=Sig)\nconf_matrix = count_table[, c(\"FALSE\", \"TRUE\")] \ncolnames(conf_matrix) = c(\"Called Not Significant\", \"Called Significant\")\nrownames(conf_matrix) = c(\"Null True\", \"Alt True\")\n\nknitr::kable(conf_matrix, caption=\"Confusion Matrix at p &lt; 0.05\")\n\n\n\nConfusion Matrix at p &lt; 0.05\n\n\n\nCalled Not Significant\nCalled Significant\n\n\n\n\nNull True\n7580\n416\n\n\nAlt True\n214\n1790\n\n\n\n\n\nShow the code\n# Extracting values\nTN = conf_matrix[\"Null True\", \"Called Not Significant\"]\nFP = conf_matrix[\"Null True\", \"Called Significant\"]\nFN = conf_matrix[\"Alt True\", \"Called Not Significant\"]\nTP = conf_matrix[\"Alt True\", \"Called Significant\"]\nprint(paste(\"TN:\", TN, \" FP:\", FP, \" FN:\", FN, \" TP:\", TP))\n\n\n[1] \"TN: 7580  FP: 416  FN: 214  TP: 1790\""
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#visualize-q-values",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#visualize-q-values",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Visualize Q-values",
    "text": "Visualize Q-values\nLet’s see if small q-values correspond to true associations (selectvec = 1).\n\n\nShow the code\nboxplot(qvec_mix ~ selectvec, main='Q-value by True Status', xlab=\"True Status (0=Null, 1=Alt)\", ylab=\"Q-value\")\ngrid()\n\n\n\n\n\n\n\n\n\nPlot sorted q-values, colored by true status.\n\n\nShow the code\nind = order(qvec_mix, decreasing=FALSE)\n# Using selectvec*2 + 1 maps 0-&gt;1 (black) and 1-&gt;3 (green) for plotting colors\nplot(sort(qvec_mix), col=selectvec[ind]*2 + 1, \n     pch=16, #selectvec[ind] + 1, \n     # lwd=selectvec[ind]*2 + 1,\n     main=\"Sorted Q-values by True Status\",\n     xlab=\"Tests ordered by Q-value\", ylab=\"Q-value\")\nlegend(\"bottomright\", legend=c(\"True Null\", \"True Alternative\"), pch=16, col=c(1, 3))\n\n\n\n\n\n\n\n\n\nQuestions: - Do small q-values tend to correspond to true alternatives (green points)? - Interpret the sorted q-value plot: What does the pattern show?\nCompare p-value and q-value distributions by true status.\n\n\nShow the code\npar(mfrow=c(1,2))\nboxplot(pvec_mix ~ selectvec, main='P-value by True Status', xlab=\"True Status (0=Null, 1=Alt)\", ylab=\"P-value\"); grid()\nboxplot(qvec_mix ~ selectvec, main='Q-value by True Status', xlab=\"True Status (0=Null, 1=Alt)\", ylab=\"Q-value\"); grid()\n\n\n\n\n\n\n\n\n\nShow the code\npar(mfrow=c(1,1))\n\n\nQuestion: Interpret these boxplots. How do q-values differ from p-values, especially for the null tests?"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#how-do-q-values-and-p-values-relate",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#how-do-q-values-and-p-values-relate",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "How Do Q-values and P-values Relate?",
    "text": "How Do Q-values and P-values Relate?\n\n\nShow the code\npar(mfrow=c(1,2))\nplot(pvec_null, qvec_null, main='Q-value vs P-value (All Null)', xlab=\"P-value\", ylab=\"Q-value\"); grid(); abline(0,1,col='red',lty=2)\nplot(pvec_mix, qvec_mix, main='Q-value vs P-value (Mixture)', xlab=\"P-value\", ylab=\"Q-value\"); grid(); abline(0,1,col='red',lty=2)\n\n\n\n\n\n\n\n\n\nShow the code\npar(mfrow=c(1,1))\n\n\nQ-values are monotonically increasing functions of p-values. Note that q-values are often ≥ p-values. The q-value can be interpreted as the FDR associated with calling that specific test significant.\nQuestions: - What is the smallest q-value when all simulations are from the null? Why? - What is the smallest q-value when simulations are from the mixture?"
  },
  {
    "objectID": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#estimating-π₀-proportion-of-true-nulls",
    "href": "post/bios-25328/2025-04-02-lecture-04/index-with-code.html#estimating-π₀-proportion-of-true-nulls",
    "title": "lecture 4 - multiple testing correction - with code",
    "section": "Estimating π₀ (Proportion of True Nulls)",
    "text": "Estimating π₀ (Proportion of True Nulls)\nThe qvalue package also estimates π₀, the overall proportion of features (tests) that are truly null.\nπ₁ = 1 - π₀ is the proportion of true alternative hypotheses.\n\n\nShow the code\n# Estimated pi0 when all tests were truly null\nprint(paste(\"Estimated pi0 (all null):\", round(qres_null$pi0, 4)))\n\n\n[1] \"Estimated pi0 (all null): 0.9582\"\n\n\nShow the code\n# Estimated pi0 for the mixed data\nprint(paste(\"Estimated pi0 (mixture):\", round(qres_mix$pi0, 4)))\n\n\n[1] \"Estimated pi0 (mixture): 0.7616\"\n\n\nShow the code\n# True proportion used in simulation\nprint(paste(\"True pi0 used:\", 1 - prop_alt))\n\n\n[1] \"True pi0 used: 0.8\"\n\n\nQuestion: How well did the qvalue package estimate the true proportion of null hypotheses (pi0) in our mixed simulation?"
  }
]