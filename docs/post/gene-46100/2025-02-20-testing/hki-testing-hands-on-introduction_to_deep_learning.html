<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>HKI Courses - Introduction to deep learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">HKI Courses</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../index-qgt.html" rel="" target="">
 <span class="menu-text">Quantitative Genomic Training</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../index-bios-25328.html" rel="" target="">
 <span class="menu-text">BIOS25328</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../index-logistics.html" rel="" target="">
 <span class="menu-text">Logistics</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#author-boxiang-liu" id="toc-author-boxiang-liu" class="nav-link active" data-scroll-target="#author-boxiang-liu">Author: Boxiang Liu</a></li>
  <li><a href="#date-03232022" id="toc-date-03232022" class="nav-link" data-scroll-target="#date-03232022">Date: 03/23/2022</a></li>
  <li><a href="#modified-03202025-by-haky-for-gene46100" id="toc-modified-03202025-by-haky-for-gene46100" class="nav-link" data-scroll-target="#modified-03202025-by-haky-for-gene46100">Modified: 03/20/2025 by Haky for GENE46100</a></li>
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#section-1-stochastic-gradient-descent" id="toc-section-1-stochastic-gradient-descent" class="nav-link" data-scroll-target="#section-1-stochastic-gradient-descent">Section 1: Stochastic Gradient Descent</a></li>
  <li><a href="#analytical-solution" id="toc-analytical-solution" class="nav-link" data-scroll-target="#analytical-solution">Analytical solution</a></li>
  <li><a href="#stochastic-gradient-descent" id="toc-stochastic-gradient-descent" class="nav-link" data-scroll-target="#stochastic-gradient-descent">Stochastic gradient descent</a>
  <ul class="collapse">
  <li><a href="#what-is-a-gradient" id="toc-what-is-a-gradient" class="nav-link" data-scroll-target="#what-is-a-gradient">What is a gradient?</a></li>
  <li><a href="#what-is-gradient-descent" id="toc-what-is-gradient-descent" class="nav-link" data-scroll-target="#what-is-gradient-descent">What is gradient descent?</a></li>
  <li><a href="#what-is-stochastic-gradient-descent" id="toc-what-is-stochastic-gradient-descent" class="nav-link" data-scroll-target="#what-is-stochastic-gradient-descent">What is stochastic gradient descent?</a></li>
  </ul></li>
  <li><a href="#three-components-of-machine-learning" id="toc-three-components-of-machine-learning" class="nav-link" data-scroll-target="#three-components-of-machine-learning">Three components of machine learning</a></li>
  <li><a href="#the-loss-function" id="toc-the-loss-function" class="nav-link" data-scroll-target="#the-loss-function">The loss function</a></li>
  <li><a href="#computing-the-gradient" id="toc-computing-the-gradient" class="nav-link" data-scroll-target="#computing-the-gradient">Computing the gradient</a>
  <ul class="collapse">
  <li><a href="#exercise-1" id="toc-exercise-1" class="nav-link" data-scroll-target="#exercise-1">Exercise 1</a></li>
  <li><a href="#exercise-2" id="toc-exercise-2" class="nav-link" data-scroll-target="#exercise-2">Exercise 2</a></li>
  </ul></li>
  <li><a href="#summary-of-section-1" id="toc-summary-of-section-1" class="nav-link" data-scroll-target="#summary-of-section-1">Summary of section 1</a></li>
  <li><a href="#section-2-multi-layer-perceptrons" id="toc-section-2-multi-layer-perceptrons" class="nav-link" data-scroll-target="#section-2-multi-layer-perceptrons">Section 2: multi-layer perceptrons</a></li>
  <li><a href="#simulation" id="toc-simulation" class="nav-link" data-scroll-target="#simulation">Simulation</a></li>
  <li><a href="#multi-layer-perceptrons" id="toc-multi-layer-perceptrons" class="nav-link" data-scroll-target="#multi-layer-perceptrons">Multi-layer perceptrons</a>
  <ul class="collapse">
  <li><a href="#question" id="toc-question" class="nav-link" data-scroll-target="#question">Question</a></li>
  </ul></li>
  <li><a href="#introducing-pytorch" id="toc-introducing-pytorch" class="nav-link" data-scroll-target="#introducing-pytorch">Introducing PyTorch</a></li>
  <li><a href="#simulation-1" id="toc-simulation-1" class="nav-link" data-scroll-target="#simulation-1">Simulation</a></li>
  <li><a href="#universal-approximation-theorem" id="toc-universal-approximation-theorem" class="nav-link" data-scroll-target="#universal-approximation-theorem">Universal approximation theorem</a></li>
  <li><a href="#summary-of-section-2" id="toc-summary-of-section-2" class="nav-link" data-scroll-target="#summary-of-section-2">Summary of section 2</a></li>
  <li><a href="#section-3-convolutional-neural-networks" id="toc-section-3-convolutional-neural-networks" class="nav-link" data-scroll-target="#section-3-convolutional-neural-networks">Section 3: Convolutional neural networks</a></li>
  <li><a href="#mlp-for-images" id="toc-mlp-for-images" class="nav-link" data-scroll-target="#mlp-for-images">MLP for Images</a></li>
  <li><a href="#convolutional-neural-networks" id="toc-convolutional-neural-networks" class="nav-link" data-scroll-target="#convolutional-neural-networks">Convolutional neural networks</a></li>
  <li><a href="#summary-of-section-3" id="toc-summary-of-section-3" class="nav-link" data-scroll-target="#summary-of-section-3">Summary of section 3</a></li>
  <li><a href="#summary-of-section-4" id="toc-summary-of-section-4" class="nav-link" data-scroll-target="#summary-of-section-4">Summary of section 4</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Introduction to deep learning</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="author-boxiang-liu" class="level3">
<h3 class="anchored" data-anchor-id="author-boxiang-liu">Author: Boxiang Liu</h3>
</section>
<section id="date-03232022" class="level3">
<h3 class="anchored" data-anchor-id="date-03232022">Date: 03/23/2022</h3>
</section>
<section id="modified-03202025-by-haky-for-gene46100" class="level3">
<h3 class="anchored" data-anchor-id="modified-03202025-by-haky-for-gene46100">Modified: 03/20/2025 by Haky for GENE46100</h3>
</section>
<section id="overview" class="level1">
<h1>Overview</h1>
<p>In this introduction to deep learning lecture, we are going to learn the following things:</p>
<ol type="1">
<li>Linear regression (baseline)</li>
<li>multi-layer perceptrons (good for non-linear relationships)</li>
<li>convolutional neural network (good for images)</li>
<li>transformers (good for long-range interaction such as sentences)</li>
</ol>
<hr>
<p>The linear model is the most commonly used model for regression problems. They follow this form:</p>
<p><span class="math inline">\(y = X\beta + \epsilon\)</span></p>
<p>where <span class="math inline">\(\epsilon \sim N(0, \sigma)\)</span></p>
<p>Let’s start with some simulated data to build a linear regression model.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">## install packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">## %pip install scikit-learn plotnine torch torchvision torchmetrics tqdm pandas torchtext</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">## imcompatibility with torchtext</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">## conda install scikit-learn plotnine</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co">## conda install pytorch torchtext torchdata torchvision -c pytorch</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="section-1-stochastic-gradient-descent" class="level1">
<h1>Section 1: Stochastic Gradient Descent</h1>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">## %pip install scikit-learn plotnine torch torchvision torchmetrics tqdm pandas torchtext</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run this command if you get ModuleNotFoundError: No module named 'sklearn'</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># %pip install scikit-learn </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Run this command if you get ModuleNotFoundError: No module named 'plotnine'</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># %pip install plotnine</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:5852,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1742491500831,&quot;user&quot;:{&quot;displayName&quot;:&quot;Hae Kyung Im&quot;,&quot;userId&quot;:&quot;15264871052778021308&quot;},&quot;user_tz&quot;:300}" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_regression</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.linalg <span class="im">import</span> inv</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine <span class="im">import</span> qplot, ggplot, geom_point, geom_line, aes</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine.themes <span class="im">import</span> theme_bw</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine.geoms <span class="im">import</span> annotate</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We simulate 1000 data points with 2 features</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:8,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1742491545220,&quot;user&quot;:{&quot;displayName&quot;:&quot;Hae Kyung Im&quot;,&quot;userId&quot;:&quot;15264871052778021308&quot;},&quot;user_tz&quot;:300}" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>bias <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>noise <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>x, y, coef <span class="op">=</span> make_regression(</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    n_features<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    n_informative<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    n_targets<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    bias<span class="op">=</span>bias,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    noise<span class="op">=</span>noise,</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    coef<span class="op">=</span><span class="va">True</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In returns above, x contains the predictors (1000 by 2), y (1000 by 1) contains the response, and coef contains the coefficients (length 2).</p>
<p>Let’s first plot the predicted vs observed values using the ground truth parameters.</p>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:7,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1742491662652,&quot;user&quot;:{&quot;displayName&quot;:&quot;Hae Kyung Im&quot;,&quot;userId&quot;:&quot;15264871052778021308&quot;},&quot;user_tz&quot;:300}" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> x.dot(coef) <span class="op">+</span> bias</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:6,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648859559114,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="016e15f6-37fc-4661-e85b-f1bbcd90c794" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>qplot(x<span class="op">=</span>y, y<span class="op">=</span>y_hat, geom<span class="op">=</span><span class="st">"point"</span>, xlab<span class="op">=</span><span class="st">"y"</span>, ylab<span class="op">=</span><span class="st">"y_hat"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="analytical-solution" class="level1">
<h1>Analytical solution</h1>
<p>We know the analytical solution to the β’s is:</p>
<p><span class="math inline">\(\hat{β} = (X^T X)^{-1} X^T y\)</span></p>
<p>This is called the <strong>normal equation</strong>.</p>
<p>Let’s get <span class="math inline">\(\hat{\beta}\)</span> and compare it with the ground truth.</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>var <span class="op">=</span> x.transpose().dot(x)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> x.transpose().dot(y)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>b_hat <span class="op">=</span> inv(var).dot(cov)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:5,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648859559114,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="36303193-30b9-46a0-f15d-9d7e10d692db" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated"</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b_hat)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Ground truth"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coef)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated
[41.06972678  6.79965716]
Ground truth
[40.71064891  6.60098441]</code></pre>
</div>
</div>
<p>The estimated is a good approximation of the ground truth, given limited sample size and noise.</p>
</section>
<section id="stochastic-gradient-descent" class="level1">
<h1>Stochastic gradient descent</h1>
<p>Although linear regression has analytical solutions, this is unfortunately not the case for many other models. We may need to resort to numerical approximations to find the optimal parameters. One of the most popular numerical optimizers is called stochastic gradient descent.</p>
<section id="what-is-a-gradient" class="level2">
<h2 class="anchored" data-anchor-id="what-is-a-gradient">What is a gradient?</h2>
<p>A gradient is the first derivative of a function.</p>
<p>$f’(β) = lim_{Δβ → 0} = $</p>
</section>
<section id="what-is-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="what-is-gradient-descent">What is gradient descent?</h2>
<p>We would like to find the <span class="math inline">\(\hat{β}\)</span> that minimizes <span class="math inline">\(f(β)\)</span>. We can do this iteratively moving along the direction of the gradient. At a particular <span class="math inline">\(β_i\)</span>, we find the gradient <span class="math inline">\(f'(β)\)</span>, and take a step along the direction of the gradient to find the next point <span class="math inline">\(β_{i+1}\)</span>.</p>
<p><span class="math inline">\(β_{i+1} = β_i - \alpha f'(β_i)\)</span></p>
<p>The <span class="math inline">\(\alpha\)</span> is called the learning rate. It is a hyperparameters that determines how fast we move in the direction of the gradient.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://i.stack.imgur.com/sRB3x.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">gradient descent</figcaption>
</figure>
</div>
</section>
<section id="what-is-stochastic-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="what-is-stochastic-gradient-descent">What is stochastic gradient descent?</h2>
<p>In real-world applications, the size of our dataset is so large that it is impossible to calculate the gradient using all data points. Therefore, we take a small chunk (called a “batch”) of the dataset to calcalate the gradient. This approximates the full-data gradients, thus the word stochastic.</p>
</section>
</section>
<section id="three-components-of-machine-learning" class="level1">
<h1>Three components of machine learning</h1>
<p>Suppose we want to build a machine learning model to predict <span class="math inline">\(y\)</span> based on <span class="math inline">\(x\)</span>. We need three components:</p>
<ol type="1">
<li>a model. In this case we use a linear model</li>
<li>a loss function.</li>
<li>an optimizer. In this case we use gradient descent or stochatic gradient descent.</li>
</ol>
</section>
<section id="the-loss-function" class="level1">
<h1>The loss function</h1>
<p>We want our prediction <span class="math inline">\(\hat{y} = f(\beta)\)</span> to be as close to <span class="math inline">\(y\)</span> as possible. Therefore, we want to minimize</p>
<p><span class="math inline">\(\ell(\beta) = \frac{1}{2}\sum\limits_{i=1}^m (f(\beta)^{(i)} - y^{(i)})^2\)</span></p>
</section>
<section id="computing-the-gradient" class="level1">
<h1>Computing the gradient</h1>
<p>For simplicity, we assume that the dataset only contains one example (x, y).</p>
<p><span class="math inline">\(\frac{\partial}{\partial \beta_j}\ell(\beta) = \frac{\partial}{\partial \beta_j} \frac{1}{2} (f(\beta) - y)^2 = (f(\beta) - y) x_j\)</span></p>
<p>Now we use this equation to perform gradient descent.</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">0.1</span> <span class="co"># learning rate</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> [<span class="fl">0.0</span>, <span class="fl">0.0</span>] <span class="co"># initialize all betas to 0</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>n_examples <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>trajectory <span class="op">=</span> [b]</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>): <span class="co"># 50 steps</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  diff <span class="op">=</span> x.dot(b) <span class="op">-</span> y</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  grad <span class="op">=</span> diff.dot(x) <span class="op">/</span> n_examples</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  b <span class="op">-=</span> lr<span class="op">*</span>grad</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  trajectory.append(b.copy())</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>trajectory <span class="op">=</span> np.stack(trajectory, axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:525,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648859559636,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="97e4a1f5-26ba-4da1-e9ea-d910d9fcd6d9" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>qplot(x<span class="op">=</span>trajectory[<span class="dv">0</span>], y<span class="op">=</span>trajectory[<span class="dv">1</span>], xlab<span class="op">=</span><span class="st">"beta_1"</span>, ylab<span class="op">=</span><span class="st">"beta_2"</span>, geom<span class="op">=</span>[<span class="st">"point"</span>, <span class="st">"line"</span>]) <span class="op">+</span> theme_bw() <span class="op">+</span> annotate(geom<span class="op">=</span><span class="st">"point"</span>, x<span class="op">=</span>coef[<span class="dv">0</span>], y<span class="op">=</span>coef[<span class="dv">1</span>], size<span class="op">=</span><span class="dv">8</span>, color<span class="op">=</span><span class="st">"blue"</span>,shape<span class="op">=</span><span class="st">'+'</span>,stroke<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
</div>
<section id="exercise-1" class="level2">
<h2 class="anchored" data-anchor-id="exercise-1">Exercise 1</h2>
<p>Add to the plot the normal equation estimates (traditional linear regression) of the coefficients in a different green</p>
</section>
<section id="exercise-2" class="level2">
<h2 class="anchored" data-anchor-id="exercise-2">Exercise 2</h2>
<p>Simulate y with larger noise, estimate the regression coefficients using the normal equation and the gradient descent method, and plot the trajectory, the ground truth, and the two estimates for comparison.</p>
</section>
</section>
<section id="summary-of-section-1" class="level1">
<h1>Summary of section 1</h1>
<p>In this section, we learned</p>
<ol type="1">
<li>The linear model</li>
<li>The normal equation</li>
<li>Stochastic gradient descent</li>
</ol>
</section>
<section id="section-2-multi-layer-perceptrons" class="level1">
<h1>Section 2: multi-layer perceptrons</h1>
</section>
<section id="simulation" class="level1">
<h1>Simulation</h1>
<p>Let’s start by simulating data according to the generative model:</p>
<p>$ y = x_1^3$</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.normal(size<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">**</span> <span class="dv">3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Let’s start with a simple linear regression model</p>
<p>$ y = X $</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">0.1</span> <span class="co"># learning rate</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="fl">0.0</span> <span class="co"># initialize all betas to 0</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>n_examples <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>): <span class="co"># 50 steps</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  diff <span class="op">=</span> x.dot(b) <span class="op">-</span> y</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  grad <span class="op">=</span> diff.dot(x) <span class="op">/</span> n_examples</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  b <span class="op">-=</span> lr<span class="op">*</span>grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:3,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648859559636,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="135a20ed-bb3f-47b1-8b52-f1b273cee12b" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> x.dot(b)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>qplot(x <span class="op">=</span> y, y<span class="op">=</span>y_hat, geom<span class="op">=</span><span class="st">"point"</span>, xlab<span class="op">=</span><span class="st">"y"</span>, ylab<span class="op">=</span><span class="st">"y_hat"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>That looks like a terrible prediction! What do we do?</p>
</section>
<section id="multi-layer-perceptrons" class="level1">
<h1>Multi-layer perceptrons</h1>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.allaboutcircuits.com/uploads/articles/an-introduction-to-training-theory-for-neural-networks_rk_aac_image2.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">MLP</figcaption>
</figure>
</div>
<p>An MLP can be thought of as multi-layer linear regression. Each circle in the hidden layer is called a “neuron”, and can be thought of as intermediate output y’s.</p>
<p>These intermediate y’s will be the input for the next layer, which will again be linearly combined to output the next layer.</p>
<p>In a hand-wavy way, we can express a 2-layer MLP as:</p>
<p><span class="math inline">\(y = W_2 (W_1 X + b_1) + b_2\)</span></p>
<section id="question" class="level2">
<h2 class="anchored" data-anchor-id="question">Question</h2>
<p>What is missing to be exactly a two layer MLP?</p>
</section>
</section>
<section id="introducing-pytorch" class="level1">
<h1>Introducing PyTorch</h1>
<p>It is cumbersome to derive the update rules for an MLP. Luckily, deep learning frameworks such as PyTorch does that automatically for us. We will build a simple PyTorch model to predict y’s based on x’s.</p>
<p>First let’s define our model. We would like to build a neural network with 3 hidden layers.</p>
</section>
<section id="simulation-1" class="level1">
<h1>Simulation</h1>
<p>Let’s first simulate some data according to this generative function.</p>
<p>$ y = _0 + _1 x_1 + _2 x_2 + ϵ$</p>
<p>Where <span class="math inline">\(\beta_0 = 5\)</span> and <span class="math inline">\(\epsilon \sim N(0,10)\)</span></p>
<div class="cell" data-execution_count="29">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">## if no ModuleNotFoundError: No module named 'torch'</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install torch torchvision</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: torch in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (2.6.0)
Collecting torchvision
  Downloading torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)
Requirement already satisfied: filelock in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (3.18.0)
Requirement already satisfied: typing-extensions&gt;=4.10.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (4.12.2)
Requirement already satisfied: networkx in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (3.4.2)
Requirement already satisfied: jinja2 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (2025.3.0)
Requirement already satisfied: setuptools in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (75.8.0)
Requirement already satisfied: sympy==1.13.1 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (1.13.1)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from sympy==1.13.1-&gt;torch) (1.3.0)
Requirement already satisfied: numpy in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torchvision) (2.2.4)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torchvision) (11.1.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from jinja2-&gt;torch) (3.0.2)
Downloading torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 12.8 MB/s eta 0:00:00
Installing collected packages: torchvision
Successfully installed torchvision-0.21.0
Note: you may need to restart the kernel to use updated packages.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">#device = torch.device("cuda")</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"mps"</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP(nn.Module):</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, hid_dim, output_dim):</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(input_dim, hid_dim)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(hid_dim, output_dim)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span>.fc1(x)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y.squeeze(<span class="dv">1</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>mlp <span class="op">=</span> MLP(input_dim<span class="op">=</span><span class="dv">1</span>, hid_dim<span class="op">=</span><span class="dv">1024</span>, output_dim<span class="op">=</span><span class="dv">1</span>).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now that we have our model, let’s define our loss function. Since we have a regression proble, we will use the mean squared error loss.</p>
<div class="cell" data-execution_count="18">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.MSELoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We also have to define our optimizer. Like before, we will use stochastic gradient descent.</p>
<div class="cell" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> SGD</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> SGD(mlp.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now we are ready to train our model.</p>
<div class="cell" data-execution_count="20">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>x_tensor <span class="op">=</span> torch.Tensor(x).unsqueeze(<span class="dv">1</span>).to(device)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>y_tensor <span class="op">=</span> torch.Tensor(y).to(device)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>  optimizer.zero_grad()</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  y_hat <span class="op">=</span> mlp(x_tensor)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>  loss <span class="op">=</span> loss_fn(y_hat, y_tensor)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  loss.backward()</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>  optimizer.step()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:314,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648859560096,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="571e5b49-d0cf-4eb5-f5ef-00516c915713" data-execution_count="21">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> mlp(x_tensor)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> y_hat.detach().cpu().numpy()</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>qplot(x<span class="op">=</span>y, y<span class="op">=</span>y_hat, geom<span class="op">=</span><span class="st">"point"</span>, xlab<span class="op">=</span><span class="st">"y"</span>, ylab<span class="op">=</span><span class="st">"y_hat"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Well, that is not really better than linear regression. Why?</p>
<p>It turns out that the a linear transformation of another linear transformation is just a linear transformation.</p>
<p><span class="math inline">\(y = W_2 (W_1 X + b_1) + b_2 = W_2 W_1 X + (W_1 b_1 + b_2) = W'X + b'\)</span></p>
<p>To make the model more expressive, we need to add some non-linear transformation.</p>
<p>The most popular linear transformation is the rectified linear unit.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://machinelearningmastery.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">relu</figcaption>
</figure>
</div>
<div class="cell" data-execution_count="22">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP(nn.Module):</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_dim, hid_dim, output_dim):</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(input_dim, hid_dim)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(hid_dim, output_dim)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> F.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y.squeeze(<span class="dv">1</span>)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>mlp <span class="op">=</span> MLP(input_dim<span class="op">=</span><span class="dv">1</span>, hid_dim<span class="op">=</span><span class="dv">1024</span>, output_dim<span class="op">=</span><span class="dv">1</span>).to(device)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> SGD(mlp.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We are now ready to train our model. To understand how our model is doing, we record the loss vs step, which is called the <strong>learning curve</strong> in ML literature.</p>
<div class="cell" data-execution_count="23">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>x_tensor <span class="op">=</span> torch.Tensor(x).unsqueeze(<span class="dv">1</span>).to(device)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>y_tensor <span class="op">=</span> torch.Tensor(y).to(device)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>learning_curve <span class="op">=</span> []</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  optimizer.zero_grad()</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>  y_hat <span class="op">=</span> mlp(x_tensor)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>  loss <span class="op">=</span> loss_fn(y_hat, y_tensor)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>  learning_curve.append(loss.item())</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>  loss.backward()</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>  optimizer.step()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:617,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648859567781,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="ed3e665c-3150-4699-892d-efd79f3ecc5d" data-execution_count="24">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>qplot(x<span class="op">=</span><span class="bu">range</span>(<span class="dv">10000</span>), y<span class="op">=</span>learning_curve, xlab<span class="op">=</span><span class="st">"epoch"</span>, ylab<span class="op">=</span><span class="st">"loss"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:442,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648859568221,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="270ae185-8d55-4e69-8581-757dfe6b4fc9" data-execution_count="26">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> mlp(x_tensor)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> y_hat.detach().cpu().numpy()</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co">#qplot(x=y, y=y_hat, geom="point", xlab="y", ylab="y_hat")</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>qplot(x<span class="op">=</span>y, y<span class="op">=</span>y_hat, geom<span class="op">=</span>[<span class="st">"point"</span>, <span class="st">"abline"</span>], </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>      xlab<span class="op">=</span><span class="st">"y"</span>, ylab<span class="op">=</span><span class="st">"y_hat"</span>,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>      abline<span class="op">=</span><span class="bu">dict</span>(slope<span class="op">=</span><span class="dv">1</span>, intercept<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'red'</span>, linetype<span class="op">=</span><span class="st">'dashed'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Now this looks much better!</p>
</section>
<section id="universal-approximation-theorem" class="level1">
<h1>Universal approximation theorem</h1>
<p>The Universal Approximation Theorem states that a neural network with 1 hidden layer can approximate any continuous function for inputs within a specific range.</p>
<p>We won’t go into details here but check out this post if you are interested: http://neuralnetworksanddeeplearning.com/chap4.html</p>
</section>
<section id="summary-of-section-2" class="level1">
<h1>Summary of section 2</h1>
<p>In section 2, we learned the following things:</p>
<ol type="1">
<li>Multi-layer perceptrons</li>
<li>basic PyTorch</li>
<li>The universal approximation theorem</li>
</ol>
</section>
<section id="section-3-convolutional-neural-networks" class="level1">
<h1>Section 3: Convolutional neural networks</h1>
<p>Let’s try to use an MLP to predict on image data.</p>
<p>We will be using the CIFAR10 dataset, The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.</p>
<p>We want to predict the object class given the image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://storage.googleapis.com/kaggle-competitions/kaggle/3649/media/cifar-10.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">cifar</figcaption>
</figure>
</div>
<div class="cell" data-execution_count="35">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install torchvision as needed</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install torch torchvision torchmetrics tqdm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: torch in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (2.6.0)
Requirement already satisfied: torchvision in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (0.21.0)
Requirement already satisfied: torchmetrics in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (1.7.0)
Collecting tqdm
  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Requirement already satisfied: filelock in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (3.18.0)
Requirement already satisfied: typing-extensions&gt;=4.10.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (4.12.2)
Requirement already satisfied: networkx in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (3.4.2)
Requirement already satisfied: jinja2 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (3.1.6)
Requirement already satisfied: fsspec in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (2025.3.0)
Requirement already satisfied: setuptools in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (75.8.0)
Requirement already satisfied: sympy==1.13.1 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torch) (1.13.1)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from sympy==1.13.1-&gt;torch) (1.3.0)
Requirement already satisfied: numpy in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torchvision) (2.2.4)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torchvision) (11.1.0)
Requirement already satisfied: packaging&gt;17.1 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torchmetrics) (24.2)
Requirement already satisfied: lightning-utilities&gt;=0.8.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from torchmetrics) (0.14.2)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from jinja2-&gt;torch) (3.0.2)
Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)
Installing collected packages: tqdm
Successfully installed tqdm-4.67.1
Note: you may need to restart the kernel to use updated packages.</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:7309,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648859575529,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="cab674d6-0069-434e-d00f-4bd77cd39a90" data-execution_count="41">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download CIFAR10 data</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> ToTensor</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> Adam</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> torchvision.datasets.CIFAR10(root<span class="op">=</span><span class="st">"."</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>ToTensor())</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> torchvision.datasets.CIFAR10(root<span class="op">=</span><span class="st">"."</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>ToTensor())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="mlp-for-images" class="level1">
<h1>MLP for Images</h1>
<p>To understand how MLP performs for MNIST, we will flatten the output to be of dimension 784 (28*28), followed by hidden layers.</p>
<div class="cell" data-execution_count="42">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP(nn.Module):</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, hid_dim):</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">3</span> <span class="op">*</span> <span class="dv">32</span> <span class="op">*</span> <span class="dv">32</span>, hid_dim)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(hid_dim, <span class="dv">10</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.flatten(x, <span class="dv">1</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> F.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> <span class="va">self</span>.fc2(x)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>mlp <span class="op">=</span> MLP(hid_dim<span class="op">=</span><span class="dv">1024</span>).to(device)</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> Adam(mlp.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="46">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchmetrics</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_data, batch_size<span class="op">=</span><span class="dv">512</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(test_data, batch_size<span class="op">=</span><span class="dv">512</span>, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>train_accuracy <span class="op">=</span> torchmetrics.Accuracy(task<span class="op">=</span><span class="st">"multiclass"</span>, num_classes<span class="op">=</span><span class="dv">10</span>).to(device)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="op">=</span> torchmetrics.Accuracy(task<span class="op">=</span><span class="st">"multiclass"</span>, num_classes<span class="op">=</span><span class="dv">10</span>).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="47">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(model):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>  learning_curve <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">100</span>)):</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    total_train_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> train_loader:</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>      optimizer.zero_grad()</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>      image, target <span class="op">=</span> batch</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>      image <span class="op">=</span> image.to(device)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>      target <span class="op">=</span> target.to(device)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>      pred <span class="op">=</span> model(image)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>      loss <span class="op">=</span> loss_fn(pred, target)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>      total_train_loss <span class="op">+=</span> loss</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>      loss.backward()</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>      optimizer.step()</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>      train_accuracy(pred, target)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>      model.<span class="bu">eval</span>()</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>      total_test_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> batch <span class="kw">in</span> test_loader:</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>        image, target <span class="op">=</span> batch</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> image.to(device)</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>        target <span class="op">=</span> target.to(device)</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> model(image)</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(pred, target)</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>        total_test_loss <span class="op">+=</span> loss</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>        test_accuracy(pred, target)</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>    learning_curve[<span class="st">"epoch"</span>].append(epoch)</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>    learning_curve[<span class="st">"train_loss"</span>].append(total_train_loss.detach().cpu().numpy()<span class="op">/</span><span class="bu">len</span>(train_loader))</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>    learning_curve[<span class="st">"test_loss"</span>].append(total_test_loss.detach().cpu().numpy()<span class="op">/</span><span class="bu">len</span>(test_loader))</span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>    learning_curve[<span class="st">"train_acc"</span>].append(train_accuracy.compute().cpu().numpy().item())</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>    learning_curve[<span class="st">"test_acc"</span>].append(test_accuracy.compute().cpu().numpy().item())</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a>    train_accuracy.reset()</span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>    test_accuracy.reset()</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> learning_curve</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:686801,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648860262319,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="05657800-a486-4c80-bcc9-4a8e2fe5e96e" data-execution_count="48">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>learning_curve <span class="op">=</span> train(mlp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 100/100 [25:06&lt;00:00, 15.07s/it]</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:644,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648860262945,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="8bf27c27-57df-477a-fa8c-462dcecb7997" data-execution_count="50">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>lc <span class="op">=</span> pd.DataFrame(learning_curve)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> pd.melt(lc.loc[:,[<span class="st">"epoch"</span>, <span class="st">"train_loss"</span>, <span class="st">"test_loss"</span>]], id_vars<span class="op">=</span><span class="st">"epoch"</span>, value_name<span class="op">=</span><span class="st">"loss"</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> pd.melt(lc.loc[:,[<span class="st">"epoch"</span>, <span class="st">"train_acc"</span>, <span class="st">"test_acc"</span>]], id_vars<span class="op">=</span><span class="st">"epoch"</span>, value_name<span class="op">=</span><span class="st">"acc"</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>ggplot(loss, aes(x<span class="op">=</span><span class="st">"epoch"</span>, y<span class="op">=</span><span class="st">"loss"</span>, color<span class="op">=</span><span class="st">"variable"</span>)) <span class="op">+</span> geom_point() <span class="op">+</span> geom_line()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-32-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:9,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648860262946,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="4137c869-f1d1-4a2d-e678-57bc5e78e2e4" data-execution_count="51">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>ggplot(acc, aes(x<span class="op">=</span><span class="st">"epoch"</span>, y<span class="op">=</span><span class="st">"acc"</span>, color<span class="op">=</span><span class="st">"variable"</span>)) <span class="op">+</span> geom_point() <span class="op">+</span> geom_line()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>You will notice that the test loss starts to rise at epoch 50. This is called overfitting. There are many ways to address this, but we won’t go into details for this introduction.</p>
<p>Test accuracy is bad. Can we do better?</p>
</section>
<section id="convolutional-neural-networks" class="level1">
<h1>Convolutional neural networks</h1>
<p>The key ingredient in CNNs is the convolutional filter. A convolutional filter is a small patch to extract a specific pattern from the input image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_02_17A-ConvolutionalNeuralNetworks-WHITEBG.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">CNN</figcaption>
</figure>
</div>
<div class="cell" data-execution_count="52">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CNN(nn.Module):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">5</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">6</span>, <span class="dv">16</span>, <span class="dv">5</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">16</span> <span class="op">*</span> <span class="dv">5</span> <span class="op">*</span> <span class="dv">5</span>, <span class="dv">120</span>)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">120</span>, <span class="dv">84</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc3 <span class="op">=</span> nn.Linear(<span class="dv">84</span>, <span class="dv">10</span>)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(F.relu(<span class="va">self</span>.conv1(x)))</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(F.relu(<span class="va">self</span>.conv2(x)))</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.flatten(x, <span class="dv">1</span>) <span class="co"># flatten all dimensions except batch</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.fc1(x))</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.fc2(x))</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc3(x)</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>cnn <span class="op">=</span> CNN().to(device)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> Adam(cnn.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:699020,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648860961960,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="7c9ac597-f630-42ee-ad95-c0f41bdec1fd" data-execution_count="53">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>cnn_learning_curve <span class="op">=</span> train(cnn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 100/100 [25:02&lt;00:00, 15.02s/it]</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:439,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648860962389,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="0046b9dd-73ea-44ac-b084-af2b2a85ae71" data-execution_count="54">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>lc <span class="op">=</span> pd.DataFrame(cnn_learning_curve)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> pd.melt(lc.loc[:,[<span class="st">"epoch"</span>, <span class="st">"train_loss"</span>, <span class="st">"test_loss"</span>]], id_vars<span class="op">=</span><span class="st">"epoch"</span>, value_name<span class="op">=</span><span class="st">"loss"</span>)</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> pd.melt(lc.loc[:,[<span class="st">"epoch"</span>, <span class="st">"train_acc"</span>, <span class="st">"test_acc"</span>]], id_vars<span class="op">=</span><span class="st">"epoch"</span>, value_name<span class="op">=</span><span class="st">"acc"</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>ggplot(loss, aes(x<span class="op">=</span><span class="st">"epoch"</span>, y<span class="op">=</span><span class="st">"loss"</span>, color<span class="op">=</span><span class="st">"variable"</span>)) <span class="op">+</span> geom_point() <span class="op">+</span> geom_line()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-36-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:252,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648860962637,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="0c0c4574-06c1-409c-d1e1-4fd10ee5e84a" data-execution_count="55">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>ggplot(acc, aes(x<span class="op">=</span><span class="st">"epoch"</span>, y<span class="op">=</span><span class="st">"acc"</span>, color<span class="op">=</span><span class="st">"variable"</span>)) <span class="op">+</span> geom_point() <span class="op">+</span> geom_line()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-37-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="56">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> count_parameters(model):</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  total_param <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> param <span class="kw">in</span> model.parameters():</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    total_param <span class="op">+=</span> param.numel()</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> total_param</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:3,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648860962637,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="8c1db0c5-f3bf-4b88-957a-5b39f77f6479" data-execution_count="58">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>mlp_params <span class="op">=</span> count_parameters(mlp)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>cnn_params <span class="op">=</span> count_parameters(cnn)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MLP: </span><span class="sc">{</span>mlp_params<span class="sc">}</span><span class="ss"> parameters"</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"CNN: </span><span class="sc">{</span>cnn_params<span class="sc">}</span><span class="ss"> parameters"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MLP: 3157002 parameters
CNN: 62006 parameters</code></pre>
</div>
</div>
<p>Here is a summary of the performance</p>
<table class="table">
<thead>
<tr class="header">
<th>Model</th>
<th>Test Accuracy</th>
<th># Parameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MLP</td>
<td>~0.5</td>
<td>315k</td>
</tr>
<tr class="even">
<td>CNN</td>
<td>~0.6</td>
<td>62k</td>
</tr>
</tbody>
</table>
<p>Remarkably, CNN achieved better performance with a smaller number of parameters.</p>
</section>
<section id="summary-of-section-3" class="level1">
<h1>Summary of section 3</h1>
<p>In section 3, we learned the following things:</p>
<ol type="1">
<li>CNNs</li>
</ol>
<div class="cell" data-execution_count="59">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Section 4: Transformers</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The transformer architecture is originally invented for machine translation (MT). MT is a structured prediction problem - the output at each timestep <span class="math inline">\(t\)</span> dependenst on the previous timesteps 1 to <span class="math inline">\(t-1\)</span>. Therefore, the transformer architecture is composed of two parts: the encoder and the decoder. The encoder will encode the source sentence (e.g.&nbsp;Spanish) into a vector representation, and the decoder will decode the vector space into the target sentence (e.g.&nbsp;English).</p>
<p>However, enformer is not a structured prediction problem, it is a regression problem. Therefore, it only needs the transformer encoder. Therefore, we will focus on the encoder today.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://www.researchgate.net/publication/334288604/figure/fig1/AS:778232232148992@1562556431066/The-Transformer-encoder-structure.ppm" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">transfomer encoder</figcaption>
</figure>
</div>
<p>You are already familiar with the feed-forward network - this is the same thing as MLP we covered earlier. But what is multi-head attention (MHA)?</p>
<p>To understand MHA, we need to know what attention is.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://windmissing.github.io/NLP-important-papers/AIAYN/assets/5.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">attention</figcaption>
</figure>
</div>
<p>Attention can be done in many ways. The transformer paper uses the dot-product attention. Suppose that we have a three tensors <span class="math inline">\(q \in R^{1, d}, K \in R^{l, d}, V \in R^{l, d}\)</span>. We will first take the softmax of the dot product of <span class="math inline">\(attn = softmax(q K^T) \in R^{1,l}\)</span>. This gives us the probability of <span class="math inline">\(q\)</span> attending to each element of <span class="math inline">\(K\)</span>. We can then take the dot product between <span class="math inline">\(attn \cdot V \in R^{1, d}\)</span>, which is a weighted sum of V.</p>
<p>This is essentially what transformer is doing. Instead of using a vector <span class="math inline">\(q\)</span>, they used a matrix <span class="math inline">\(Q\)</span> for parallel computation.</p>
<p>So what does multi-head mean? It just means that we have multiple attention mechanisms. Before the feedforward layer, we will concatenate the multiple attention heads.</p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install torchtext</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: torchtext in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (0.18.0)
Requirement already satisfied: tqdm in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from torchtext) (4.67.1)
Requirement already satisfied: requests in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from torchtext) (2.32.3)
Requirement already satisfied: torch&gt;=2.3.0 in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from torchtext) (2.6.0)
Requirement already satisfied: numpy in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from torchtext) (2.2.4)
Requirement already satisfied: filelock in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from torch&gt;=2.3.0-&gt;torchtext) (3.18.0)
Requirement already satisfied: typing-extensions&gt;=4.10.0 in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from torch&gt;=2.3.0-&gt;torchtext) (4.12.2)
Requirement already satisfied: networkx in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from torch&gt;=2.3.0-&gt;torchtext) (3.4.2)
Requirement already satisfied: jinja2 in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from torch&gt;=2.3.0-&gt;torchtext) (3.1.6)
Requirement already satisfied: fsspec in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from torch&gt;=2.3.0-&gt;torchtext) (2025.3.0)
Requirement already satisfied: sympy==1.13.1 in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from torch&gt;=2.3.0-&gt;torchtext) (1.13.1)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from sympy==1.13.1-&gt;torch&gt;=2.3.0-&gt;torchtext) (1.3.0)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from requests-&gt;torchtext) (3.4.1)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from requests-&gt;torchtext) (3.10)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from requests-&gt;torchtext) (2.3.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from requests-&gt;torchtext) (2025.1.31)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /Users/haekyungim/miniconda3/envs/torch311/lib/python3.11/site-packages (from jinja2-&gt;torch&gt;=2.3.0-&gt;torchtext) (3.0.2)
Note: you may need to restart the kernel to use updated packages.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>   <span class="im">import</span> torch</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>   <span class="im">import</span> torchtext</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>   <span class="bu">print</span>(torch.__version__)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>   <span class="bu">print</span>(torchtext.__version__)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>2.3.1
0.6.0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchtext</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Dataset</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter, defaultdict</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn.utils.rnn <span class="im">import</span> pad_sequence</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> Adam</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchmetrics</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Get dataset</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>imdb_train <span class="op">=</span> <span class="bu">list</span>(torchtext.datasets.IMDB(root<span class="op">=</span><span class="st">"."</span>, split<span class="op">=</span><span class="st">"train"</span>))</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>imdb_test <span class="op">=</span> <span class="bu">list</span>(torchtext.datasets.IMDB(root<span class="op">=</span><span class="st">"."</span>, split<span class="op">=</span><span class="st">"test"</span>))</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>)</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>train_accuracy <span class="op">=</span> torchmetrics.Accuracy().to(device)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="op">=</span> torchmetrics.Accuracy().to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-error">
<pre><code>TypeError: IMDB.__init__() missing 3 required positional arguments: 'path', 'text_field', and 'label_field'</code></pre>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get tokenizer</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> torchtext.data.utils.get_tokenizer(<span class="st">"basic_english"</span>)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Build vocabulary</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>counter <span class="op">=</span> Counter()</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>max_len <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (label, line) <span class="kw">in</span> imdb_train:</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>  tokenized <span class="op">=</span> tokenizer(line)</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>  counter.update(tokenized)</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>vocab <span class="op">=</span> torchtext.vocab.vocab(counter, min_freq<span class="op">=</span><span class="dv">10</span>, specials<span class="op">=</span>(<span class="st">'&lt;unk&gt;'</span>, <span class="st">'&lt;CLS&gt;'</span>, <span class="st">'&lt;EOS&gt;'</span>, <span class="st">'&lt;PAD&gt;'</span>))</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>vocab.set_default_index(vocab[<span class="st">'&lt;unk&gt;'</span>])</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformations:</span></span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>text_transform <span class="op">=</span> <span class="kw">lambda</span> x: [vocab[<span class="st">'&lt;CLS&gt;'</span>]] <span class="op">+</span> [vocab[token] <span class="cf">for</span> token <span class="kw">in</span> tokenizer(x)][:max_len<span class="op">-</span><span class="dv">2</span>] <span class="op">+</span> [vocab[<span class="st">'&lt;EOS&gt;'</span>]]</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>label_transform <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">1</span> <span class="cf">if</span> x <span class="op">==</span> <span class="st">'pos'</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Collate function</span></span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> collate_batch(batch):</span>
<span id="cb53-19"><a href="#cb53-19" aria-hidden="true" tabindex="-1"></a>   label_list, text_list <span class="op">=</span> [], []</span>
<span id="cb53-20"><a href="#cb53-20" aria-hidden="true" tabindex="-1"></a>   <span class="cf">for</span> (_label, _text) <span class="kw">in</span> batch:</span>
<span id="cb53-21"><a href="#cb53-21" aria-hidden="true" tabindex="-1"></a>        label_list.append(label_transform(_label))</span>
<span id="cb53-22"><a href="#cb53-22" aria-hidden="true" tabindex="-1"></a>        processed_text <span class="op">=</span> torch.tensor(text_transform(_text))</span>
<span id="cb53-23"><a href="#cb53-23" aria-hidden="true" tabindex="-1"></a>        text_list.append(processed_text)</span>
<span id="cb53-24"><a href="#cb53-24" aria-hidden="true" tabindex="-1"></a>   <span class="cf">return</span> torch.tensor(label_list), pad_sequence(text_list, padding_value<span class="op">=</span><span class="fl">3.0</span>)</span>
<span id="cb53-25"><a href="#cb53-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-26"><a href="#cb53-26" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> IMDBDataset(Dataset):</span>
<span id="cb53-27"><a href="#cb53-27" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data):</span>
<span id="cb53-28"><a href="#cb53-28" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.data <span class="op">=</span> data</span>
<span id="cb53-29"><a href="#cb53-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-30"><a href="#cb53-30" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb53-31"><a href="#cb53-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.data)</span>
<span id="cb53-32"><a href="#cb53-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-33"><a href="#cb53-33" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span>
<span id="cb53-34"><a href="#cb53-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span>.data[index]</span>
<span id="cb53-35"><a href="#cb53-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-36"><a href="#cb53-36" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> IMDBDataset(imdb_train)</span>
<span id="cb53-37"><a href="#cb53-37" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> IMDBDataset(imdb_test)</span>
<span id="cb53-38"><a href="#cb53-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-39"><a href="#cb53-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Get DataLoader</span></span>
<span id="cb53-40"><a href="#cb53-40" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>, collate_fn<span class="op">=</span>collate_batch, drop_last<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb53-41"><a href="#cb53-41" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span>batch_size, collate_fn<span class="op">=</span>collate_batch)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>dclass SentimentPredictor(nn.Module):</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, embed_dim<span class="op">=</span><span class="dv">64</span>, nhead<span class="op">=</span><span class="dv">1</span>, dim_feedforward<span class="op">=</span><span class="dv">128</span>, layers<span class="op">=</span><span class="dv">2</span>, dropout<span class="op">=</span><span class="fl">0.5</span>):</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.token_embedding <span class="op">=</span> nn.Embedding(num_embeddings<span class="op">=</span><span class="bu">len</span>(vocab), embedding_dim<span class="op">=</span>embed_dim, padding_idx<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.pos_embedding <span class="op">=</span> nn.Embedding(num_embeddings<span class="op">=</span>max_len, embedding_dim<span class="op">=</span>embed_dim)</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.encoder_layer <span class="op">=</span> nn.TransformerEncoderLayer(embed_dim, nhead<span class="op">=</span>nhead, dim_feedforward<span class="op">=</span>dim_feedforward, norm_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.encoder <span class="op">=</span> nn.TransformerEncoder(encoder_layer<span class="op">=</span><span class="va">self</span>.encoder_layer, num_layers<span class="op">=</span>layers)</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(embed_dim, <span class="dv">2</span>)</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> forward(<span class="va">self</span>, batch):</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> batch.shape[<span class="dv">1</span>]</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>    text_len <span class="op">=</span> batch.shape[<span class="dv">0</span>]</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> torch.arange(text_len).unsqueeze(<span class="dv">1</span>).repeat(<span class="dv">1</span>, batch_size).type_as(batch)</span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>    token_embedded <span class="op">=</span> <span class="va">self</span>.token_embedding(batch)</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>    pos_embedded <span class="op">=</span> <span class="va">self</span>.pos_embedding(pos)</span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>    embedded <span class="op">=</span> <span class="va">self</span>.dropout(token_embedded <span class="op">+</span> pos_embedded)</span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> <span class="va">self</span>.encoder(embedded)</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span>.fc(<span class="va">self</span>.dropout(output[<span class="dv">0</span>]))</span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SentimentPredictor().to(device)</span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> Adam(model.parameters())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="bu">eval</span>(model, test_loader):</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>  total_test_loss <span class="op">=</span> []</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">with</span> torch.no_grad():</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label, text <span class="kw">in</span> <span class="bu">list</span>(test_loader):</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>      label <span class="op">=</span> label.to(device)</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>      text <span class="op">=</span> text.to(device)</span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>      pred <span class="op">=</span> model(text)</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>      loss <span class="op">=</span> loss_fn(pred, label)</span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>      total_test_loss.append(loss.item())</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>      test_accuracy(pred, label)</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> total_test_loss</span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(model, train_loader, test_loader):</span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a>  learning_curve <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>  step <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb55-20"><a href="#cb55-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-21"><a href="#cb55-21" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb55-22"><a href="#cb55-22" aria-hidden="true" tabindex="-1"></a>    total_train_loss <span class="op">=</span> []</span>
<span id="cb55-23"><a href="#cb55-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label, text <span class="kw">in</span> tqdm(train_loader):</span>
<span id="cb55-24"><a href="#cb55-24" aria-hidden="true" tabindex="-1"></a>      step <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb55-25"><a href="#cb55-25" aria-hidden="true" tabindex="-1"></a>      optimizer.zero_grad()</span>
<span id="cb55-26"><a href="#cb55-26" aria-hidden="true" tabindex="-1"></a>      label <span class="op">=</span> label.to(device)</span>
<span id="cb55-27"><a href="#cb55-27" aria-hidden="true" tabindex="-1"></a>      text <span class="op">=</span> text.to(device)</span>
<span id="cb55-28"><a href="#cb55-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-29"><a href="#cb55-29" aria-hidden="true" tabindex="-1"></a>      pred <span class="op">=</span> model(text)</span>
<span id="cb55-30"><a href="#cb55-30" aria-hidden="true" tabindex="-1"></a>      loss <span class="op">=</span> loss_fn(pred, label)</span>
<span id="cb55-31"><a href="#cb55-31" aria-hidden="true" tabindex="-1"></a>      total_train_loss.append(loss.item())</span>
<span id="cb55-32"><a href="#cb55-32" aria-hidden="true" tabindex="-1"></a>      loss.backward()</span>
<span id="cb55-33"><a href="#cb55-33" aria-hidden="true" tabindex="-1"></a>      optimizer.step()</span>
<span id="cb55-34"><a href="#cb55-34" aria-hidden="true" tabindex="-1"></a>      train_accuracy(pred, label)</span>
<span id="cb55-35"><a href="#cb55-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-36"><a href="#cb55-36" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> step <span class="op">%</span> <span class="dv">200</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb55-37"><a href="#cb55-37" aria-hidden="true" tabindex="-1"></a>        total_test_loss <span class="op">=</span> <span class="bu">eval</span>(model, test_loader)</span>
<span id="cb55-38"><a href="#cb55-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-39"><a href="#cb55-39" aria-hidden="true" tabindex="-1"></a>        learning_curve[<span class="st">"step"</span>].append(step)</span>
<span id="cb55-40"><a href="#cb55-40" aria-hidden="true" tabindex="-1"></a>        learning_curve[<span class="st">"train_loss"</span>].append(np.mean(total_train_loss))</span>
<span id="cb55-41"><a href="#cb55-41" aria-hidden="true" tabindex="-1"></a>        learning_curve[<span class="st">"test_loss"</span>].append(np.mean(total_test_loss))</span>
<span id="cb55-42"><a href="#cb55-42" aria-hidden="true" tabindex="-1"></a>        learning_curve[<span class="st">"train_acc"</span>].append(train_accuracy.compute().cpu().numpy().item())</span>
<span id="cb55-43"><a href="#cb55-43" aria-hidden="true" tabindex="-1"></a>        learning_curve[<span class="st">"test_acc"</span>].append(test_accuracy.compute().cpu().numpy().item())</span>
<span id="cb55-44"><a href="#cb55-44" aria-hidden="true" tabindex="-1"></a>        train_accuracy.reset()</span>
<span id="cb55-45"><a href="#cb55-45" aria-hidden="true" tabindex="-1"></a>        test_accuracy.reset()</span>
<span id="cb55-46"><a href="#cb55-46" aria-hidden="true" tabindex="-1"></a>        total_train_loss <span class="op">=</span> []</span>
<span id="cb55-47"><a href="#cb55-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-48"><a href="#cb55-48" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> learning_curve</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:363541,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648861331311,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="45255a11-4c8f-4e4e-b79d-075715003bc1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>transformer_learning_curve <span class="op">=</span> train(model, train_loader, test_loader)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>epoch: 0
epoch: 1
epoch: 2</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 1562/1562 [01:52&lt;00:00, 13.84it/s]
100%|██████████| 1562/1562 [02:05&lt;00:00, 12.48it/s]
100%|██████████| 1562/1562 [02:05&lt;00:00, 12.45it/s]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="49">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pandas plotnine</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Requirement already satisfied: pandas in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (2.2.3)
Requirement already satisfied: plotnine in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (0.14.5)
Requirement already satisfied: numpy&gt;=1.26.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from pandas) (2.2.4)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from pandas) (2025.1)
Requirement already satisfied: tzdata&gt;=2022.7 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from pandas) (2025.1)
Requirement already satisfied: matplotlib&gt;=3.8.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from plotnine) (3.10.1)
Requirement already satisfied: mizani~=0.13.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from plotnine) (0.13.1)
Requirement already satisfied: scipy&gt;=1.8.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from plotnine) (1.15.2)
Requirement already satisfied: statsmodels&gt;=0.14.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from plotnine) (0.14.4)
Requirement already satisfied: contourpy&gt;=1.0.1 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from matplotlib&gt;=3.8.0-&gt;plotnine) (1.3.1)
Requirement already satisfied: cycler&gt;=0.10 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from matplotlib&gt;=3.8.0-&gt;plotnine) (0.12.1)
Requirement already satisfied: fonttools&gt;=4.22.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from matplotlib&gt;=3.8.0-&gt;plotnine) (4.56.0)
Requirement already satisfied: kiwisolver&gt;=1.3.1 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from matplotlib&gt;=3.8.0-&gt;plotnine) (1.4.8)
Requirement already satisfied: packaging&gt;=20.0 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from matplotlib&gt;=3.8.0-&gt;plotnine) (24.2)
Requirement already satisfied: pillow&gt;=8 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from matplotlib&gt;=3.8.0-&gt;plotnine) (11.1.0)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from matplotlib&gt;=3.8.0-&gt;plotnine) (3.2.1)
Requirement already satisfied: six&gt;=1.5 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.17.0)
Requirement already satisfied: patsy&gt;=0.5.6 in /Users/haekyungim/miniconda3/envs/test312/lib/python3.12/site-packages (from statsmodels&gt;=0.14.0-&gt;plotnine) (1.0.1)
Note: you may need to restart the kernel to use updated packages.</code></pre>
</div>
</div>
<div class="cell" data-executioninfo="{&quot;elapsed&quot;:4,&quot;status&quot;:&quot;ok&quot;,&quot;timestamp&quot;:1648861331587,&quot;user&quot;:{&quot;displayName&quot;:&quot;Boxiang Liu&quot;,&quot;userId&quot;:&quot;15524787135066631097&quot;},&quot;user_tz&quot;:420}" data-outputid="a97fcf0d-69c0-4ea2-d1d6-5c5623364a86">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine <span class="im">import</span> qplot, ggplot, geom_point, geom_line, aes</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine.themes <span class="im">import</span> theme_bw</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotnine.geoms <span class="im">import</span> annotate</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>lc <span class="op">=</span> pd.DataFrame(transformer_learning_curve)</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> pd.melt(lc.loc[:,[<span class="st">"step"</span>, <span class="st">"train_loss"</span>, <span class="st">"test_loss"</span>]], id_vars<span class="op">=</span><span class="st">"step"</span>, value_name<span class="op">=</span><span class="st">"loss"</span>)</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> pd.melt(lc.loc[:,[<span class="st">"step"</span>, <span class="st">"train_acc"</span>, <span class="st">"test_acc"</span>]], id_vars<span class="op">=</span><span class="st">"step"</span>, value_name<span class="op">=</span><span class="st">"acc"</span>)</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>ggplot(acc, aes(x<span class="op">=</span><span class="st">"step"</span>, y<span class="op">=</span><span class="st">"acc"</span>, color<span class="op">=</span><span class="st">"variable"</span>)) <span class="op">+</span> geom_point() <span class="op">+</span> geom_line()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.7/dist-packages/plotnine/utils.py:1246: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead
  if pdtypes.is_categorical(arr):</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="hki-testing-hands-on-introduction_to_deep_learning_files/figure-html/cell-50-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="summary-of-section-4" class="level1">
<h1>Summary of section 4</h1>
<p>In section 4, we have learned the following:</p>
<ol type="1">
<li>the attention mechanism</li>
<li>basic natural language processing</li>
<li>the transformer encoder architecture</li>
</ol>


</section>

<p>© <a href="https://hakyimlab.org">HakyImLab and Listed Authors</a> - <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 License</a></p></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>